//! åœé¡¿æ£€æµ‹å¼•æ“
//!
//! åŸºäº VAD æ—¶é—´æˆ³å’Œ token æ—¶é•¿æ£€æµ‹åœé¡¿ï¼Œåˆ¤æ–­æ˜¯å¦æ’å…¥é€—å·

use crate::punctuation::config::StyleProfile;
use std::time::Duration;

/// Token ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct TokenInfo {
    /// Token æ–‡æœ¬
    pub text: String,
    /// Token å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub start_ms: u64,
    /// Token ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub end_ms: u64,
}

impl TokenInfo {
    /// åˆ›å»ºæ–°çš„ TokenInfo
    pub fn new(text: String, start_ms: u64, end_ms: u64) -> Self {
        Self {
            text,
            start_ms,
            end_ms,
        }
    }

    /// Token æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pub fn duration_ms(&self) -> u64 {
        self.end_ms.saturating_sub(self.start_ms)
    }
}

/// åœé¡¿æ£€æµ‹å¼•æ“
pub struct PauseEngine {
    profile: StyleProfile,
    token_history: Vec<TokenInfo>,
    last_comma_position: Option<usize>,
}

impl PauseEngine {
    /// åˆ›å»ºæ–°çš„åœé¡¿æ£€æµ‹å¼•æ“
    pub fn new(profile: StyleProfile) -> Self {
        Self {
            profile,
            token_history: Vec::new(),
            last_comma_position: None,
        }
    }

    /// æ·»åŠ æ–° token
    ///
    /// è¿”å›æ˜¯å¦åº”è¯¥åœ¨æ­¤ token å‰æ’å…¥é€—å·
    pub fn add_token(&mut self, token: TokenInfo) -> bool {
        let should_insert = self.should_insert_comma(&token);

        if should_insert {
            tracing::debug!("  ğŸ¯ æ£€æµ‹åˆ°åœé¡¿ï¼Œå°†åœ¨ '{}' å‰æ’å…¥é€—å·", token.text);
            self.last_comma_position = Some(self.token_history.len());
        }

        self.token_history.push(token);
        should_insert
    }

    /// åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’å…¥é€—å·
    fn should_insert_comma(&self, token: &TokenInfo) -> bool {
        // æ£€æŸ¥ token æ•°é‡
        if self.token_history.len() < self.profile.streaming_min_tokens {
            return false;
        }

        // æ£€æŸ¥è·ç¦»ä¸Šæ¬¡é€—å·çš„ token æ•°
        if let Some(last_pos) = self.last_comma_position {
            let tokens_since_comma = self.token_history.len() - last_pos;
            if tokens_since_comma < self.profile.min_tokens_between_commas {
                return false;
            }
        }

        // Sherpa-ONNX çš„ timestamps æ˜¯è¿ç»­çš„ï¼ŒToken ä¹‹é—´æ²¡æœ‰é—´éš™
        // åœé¡¿åŒ…å«åœ¨ä¸Šä¸€ä¸ª Token çš„æ—¶é•¿ä¸­
        // å› æ­¤æˆ‘ä»¬æ£€æµ‹ä¸Šä¸€ä¸ª Token çš„æ—¶é•¿æ˜¯å¦å¼‚å¸¸é•¿
        if let Some(last_token) = self.token_history.last() {
            let last_token_duration = last_token.duration_ms();

            // æ£€æŸ¥æœ€å°æ—¶é•¿ï¼ˆé¿å…è¯¯åˆ¤çŸ­ Tokenï¼‰
            if last_token_duration < self.profile.min_pause_duration_ms {
                tracing::debug!("    â­  ä¸Šä¸€Token '{}' æ—¶é•¿ {}ms < æœ€å°é˜ˆå€¼ {}msï¼Œè·³è¿‡",
                    last_token.text, last_token_duration, self.profile.min_pause_duration_ms);
                return false;
            }

            // è®¡ç®—å¹³å‡ token æ—¶é•¿
            let avg_duration = self.calculate_avg_token_duration();
            if avg_duration == 0 {
                return false;
            }

            // è®¡ç®—æ—¶é•¿æ¯”ä¾‹ï¼ˆä¸Šä¸€ä¸ª Token çš„æ—¶é•¿ / å¹³å‡æ—¶é•¿ï¼‰
            let duration_ratio = last_token_duration as f32 / avg_duration as f32;

            tracing::debug!("    â±  åœé¡¿æ£€æµ‹: ä¸Šä¸€Token='{}' æ—¶é•¿={}ms, å¹³å‡={}ms, æ¯”ä¾‹={:.2}, é˜ˆå€¼={:.2}",
                last_token.text, last_token_duration, avg_duration, duration_ratio, self.profile.streaming_pause_ratio);

            // å¦‚æœä¸Šä¸€ä¸ª Token çš„æ—¶é•¿æ˜¾è‘—è¶…è¿‡å¹³å‡å€¼ï¼Œè¯´æ˜åŒ…å«äº†åœé¡¿
            // åœ¨å½“å‰ Token å‰æ’å…¥é€—å·
            return duration_ratio > self.profile.streaming_pause_ratio;
        }

        false
    }

    /// è®¡ç®—æœ€è¿‘ N ä¸ª token çš„å¹³å‡æ—¶é•¿
    fn calculate_avg_token_duration(&self) -> u64 {
        const WINDOW_SIZE: usize = 10;

        let window = if self.token_history.len() > WINDOW_SIZE {
            &self.token_history[self.token_history.len() - WINDOW_SIZE..]
        } else {
            &self.token_history[..]
        };

        if window.is_empty() {
            return 0;
        }

        let total: u64 = window.iter().map(|t| t.duration_ms()).sum();
        total / window.len() as u64
    }

    /// é‡ç½®å¼•æ“ï¼ˆç”¨äºæ–°çš„ VAD æ®µï¼‰
    pub fn reset(&mut self) {
        self.token_history.clear();
        self.last_comma_position = None;
    }

    /// è·å–å½“å‰ token æ•°é‡
    pub fn token_count(&self) -> usize {
        self.token_history.len()
    }

    /// æ›´æ–°é…ç½®
    pub fn update_profile(&mut self, profile: StyleProfile) {
        self.profile = profile;
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_pause_engine_basic() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        // æ·»åŠ ç¬¬ä¸€ä¸ª token - ä¸åº”æ’å…¥é€—å·ï¼ˆtoken æ•°ä¸è¶³ï¼‰
        assert!(!engine.add_token(TokenInfo::new("ä½ å¥½".to_string(), 0, 200)));
    }

    #[test]
    fn test_pause_engine_min_tokens() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        // æ·»åŠ  5 ä¸ª tokenï¼ˆå°äº min_tokens: 6ï¼‰
        for i in 0..5 {
            let token = TokenInfo::new(
                format!("token{}", i),
                i * 200,
                i * 200 + 180,
            );
            assert!(!engine.add_token(token));
        }

        assert_eq!(engine.token_count(), 5);
    }

    #[test]
    fn test_pause_engine_with_pause() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        // æ·»åŠ  6 ä¸ªæ­£å¸¸ token
        for i in 0..6 {
            let token = TokenInfo::new(
                format!("token{}", i),
                i * 200,
                i * 200 + 180,
            );
            assert!(!engine.add_token(token));
        }

        // æ·»åŠ ä¸€ä¸ªå¸¦é•¿åœé¡¿çš„ token
        // ä¸Šä¸€ä¸ª token ç»“æŸäº 1180ms
        // è¿™ä¸ª token å¼€å§‹äº 2000msï¼Œåœé¡¿ 820ms
        // å¹³å‡ token æ—¶é•¿çº¦ 180msï¼Œåœé¡¿æ¯”ä¾‹ = 820/180 â‰ˆ 4.5 > 3.5
        let paused_token = TokenInfo::new(
            "next".to_string(),
            2000,
            2180,
        );
        assert!(engine.add_token(paused_token));
    }

    #[test]
    fn test_pause_engine_min_tokens_between_commas() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        // æ·»åŠ  6 ä¸ª token
        for i in 0..6 {
            engine.add_token(TokenInfo::new(
                format!("token{}", i),
                i * 200,
                i * 200 + 180,
            ));
        }

        // è§¦å‘ç¬¬ä¸€ä¸ªé€—å·
        engine.add_token(TokenInfo::new("next".to_string(), 2000, 2180));

        // ç«‹å³å°è¯•è§¦å‘ç¬¬äºŒä¸ªé€—å·ï¼ˆä½† tokens_since_comma < 4ï¼‰
        let token2 = TokenInfo::new("another".to_string(), 3000, 3180);
        assert!(!engine.add_token(token2));
    }

    #[test]
    fn test_pause_engine_reset() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        engine.add_token(TokenInfo::new("test".to_string(), 0, 200));
        assert_eq!(engine.token_count(), 1);

        engine.reset();
        assert_eq!(engine.token_count(), 0);
    }

    #[test]
    fn test_calculate_avg_duration() {
        let mut engine = PauseEngine::new(StyleProfile::professional());

        // æ·»åŠ  3 ä¸ª tokenï¼Œæ—¶é•¿åˆ†åˆ«ä¸º 100ms, 200ms, 300ms
        engine.add_token(TokenInfo::new("t1".to_string(), 0, 100));
        engine.add_token(TokenInfo::new("t2".to_string(), 100, 300));
        engine.add_token(TokenInfo::new("t3".to_string(), 300, 600));

        let avg = engine.calculate_avg_token_duration();
        assert_eq!(avg, (100 + 200 + 300) / 3); // 200ms
    }

    #[test]
    fn test_token_info_duration() {
        let token = TokenInfo::new("test".to_string(), 100, 350);
        assert_eq!(token.duration_ms(), 250);
    }
}
