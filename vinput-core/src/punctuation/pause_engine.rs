//! åœé¡¿æ£€æµ‹å¼•æ“
//!
//! åŸºäº VAD æ—¶é—´æˆ³å’Œ token æ—¶é•¿æ£€æµ‹åœé¡¿ï¼Œåˆ¤æ–­æ˜¯å¦æ’å…¥é€—å·

use crate::punctuation::config::StyleProfile;

/// Token ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct TokenInfo {
    /// Token æ–‡æœ¬
    pub text: String,
    /// Token å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub start_ms: u64,
    /// Token ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub end_ms: u64,
}

impl TokenInfo {
    /// åˆ›å»ºæ–°çš„ TokenInfo
    pub fn new(text: String, start_ms: u64, end_ms: u64) -> Self {
        Self {
            text,
            start_ms,
            end_ms,
        }
    }

    /// Token æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pub fn duration_ms(&self) -> u64 {
        self.end_ms.saturating_sub(self.start_ms)
    }
}

/// Token å¤„ç†ç»“æœ
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TokenAction {
    /// è·³è¿‡æ­¤ tokenï¼ˆæ—¶é•¿è¿‡çŸ­ï¼‰
    Skip,
    /// æ­£å¸¸æ·»åŠ  token
    Normal,
    /// åœ¨ token å‰æ’å…¥é€—å·
    InsertComma,
}

/// åœé¡¿æ£€æµ‹å¼•æ“
pub struct PauseEngine {
    profile: StyleProfile,
    token_history: Vec<TokenInfo>,
    last_comma_position: Option<usize>,
}

impl PauseEngine {
    /// åˆ›å»ºæ–°çš„åœé¡¿æ£€æµ‹å¼•æ“
    pub fn new(profile: StyleProfile) -> Self {
        Self {
            profile,
            token_history: Vec::new(),
            last_comma_position: None,
        }
    }

    /// æ·»åŠ æ–° token
    ///
    /// è¿”å› Token å¤„ç†åŠ¨ä½œ
    pub fn add_token(&mut self, token: TokenInfo) -> TokenAction {
        // âœ… æ£€æŸ¥ token å†…å®¹ï¼Œè¿‡æ»¤ç©ºç™½å­—ç¬¦å’Œæ— æ„ä¹‰å­—ç¬¦
        let trimmed = token.text.trim();
        if trimmed.is_empty() || trimmed == " " || trimmed == "NE" {
            tracing::debug!("    â­  Token '{}' æ˜¯ç©ºç™½æˆ–æ— æ„ä¹‰å­—ç¬¦ï¼Œè·³è¿‡", token.text);
            // ä¸æ·»åŠ åˆ°å†å²ï¼Œç›´æ¥è·³è¿‡
            return TokenAction::Skip;
        }

        let should_insert = self.should_insert_comma(&token);

        if should_insert {
            tracing::debug!("  ğŸ¯ æ£€æµ‹åˆ°åœé¡¿ï¼Œå°†åœ¨ '{}' å‰æ’å…¥é€—å·", token.text);
            self.last_comma_position = Some(self.token_history.len());
        }

        self.token_history.push(token);

        if should_insert {
            TokenAction::InsertComma
        } else {
            TokenAction::Normal
        }
    }

    /// åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’å…¥é€—å·
    fn should_insert_comma(&self, token: &TokenInfo) -> bool {
        // æ£€æŸ¥ token æ•°é‡
        if self.token_history.len() < self.profile.streaming_min_tokens {
            return false;
        }

        // æ£€æŸ¥è·ç¦»ä¸Šæ¬¡é€—å·çš„ token æ•°
        if let Some(last_pos) = self.last_comma_position {
            let tokens_since_comma = self.token_history.len() - last_pos;
            if tokens_since_comma < self.profile.min_tokens_between_commas {
                return false;
            }
        }

        if let Some(last_token) = self.token_history.last() {
            // æ–¹æ³•1ï¼šæ£€æŸ¥ç›¸é‚» Token æ—¶é—´é—´éš™
            // sherpa-onnx çš„åœé¡¿æ›´å¯é åœ°ä½“ç°åœ¨ end_ms â†’ start_ms çš„ç©ºç™½ä¸Š
            let gap_ms = token.start_ms.saturating_sub(last_token.end_ms);
            if gap_ms >= 200 {
                tracing::debug!("  ğŸ¯ åœé¡¿æ£€æµ‹(é—´éš™æ³•): '{}' å‰æœ‰ {}ms é—´éš™ >= 200msï¼Œæ’å…¥é€—å·",
                    token.text, gap_ms);
                return true;
            }

            // æ–¹æ³•2ï¼šæ£€æŸ¥ä¸Šä¸€ä¸ª Token æ—¶é•¿æ¯”ä¾‹ï¼ˆtimestamps è¿ç»­æ—¶çš„å¤‡ç”¨æ–¹æ³•ï¼‰
            // Sherpa-ONNX çš„ timestamps è¿ç»­æ—¶ï¼Œåœé¡¿åŒ…å«åœ¨ä¸Šä¸€ä¸ª Token çš„æ—¶é•¿ä¸­
            let last_token_duration = last_token.duration_ms();

            if last_token_duration < self.profile.min_pause_duration_ms {
                tracing::debug!("    â­  ä¸Šä¸€Token '{}' æ—¶é•¿ {}ms < æœ€å°åœé¡¿é˜ˆå€¼ {}msï¼Œä¸æ£€æµ‹åœé¡¿",
                    last_token.text, last_token_duration, self.profile.min_pause_duration_ms);
                return false;
            }

            let avg_duration = self.calculate_avg_token_duration();
            if avg_duration == 0 {
                return false;
            }

            let duration_ratio = last_token_duration as f32 / avg_duration as f32;

            tracing::debug!("    â±  åœé¡¿æ£€æµ‹(æ—¶é•¿æ³•): ä¸Šä¸€Token='{}' æ—¶é•¿={}ms, å¹³å‡={}ms, æ¯”ä¾‹={:.2}, é˜ˆå€¼={:.2}",
                last_token.text, last_token_duration, avg_duration, duration_ratio, self.profile.streaming_pause_ratio);

            return duration_ratio > self.profile.streaming_pause_ratio;
        }

        false
    }

    /// è®¡ç®—æœ€è¿‘ N ä¸ª token çš„å¹³å‡æ—¶é•¿
    fn calculate_avg_token_duration(&self) -> u64 {
        const WINDOW_SIZE: usize = 10;

        let window = if self.token_history.len() > WINDOW_SIZE {
            &self.token_history[self.token_history.len() - WINDOW_SIZE..]
        } else {
            &self.token_history[..]
        };

        if window.is_empty() {
            return 0;
        }

        let total: u64 = window.iter().map(|t| t.duration_ms()).sum();
        total / window.len() as u64
    }

    /// é‡ç½®å¼•æ“ï¼ˆç”¨äºæ–°çš„ VAD æ®µï¼‰
    pub fn reset(&mut self) {
        self.token_history.clear();
        self.last_comma_position = None;
    }

    /// è·å–å½“å‰ token æ•°é‡
    pub fn token_count(&self) -> usize {
        self.token_history.len()
    }

    /// æ›´æ–°é…ç½®
    pub fn update_profile(&mut self, profile: StyleProfile) {
        self.profile = profile;
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_pause_engine_basic() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // æ·»åŠ ç¬¬ä¸€ä¸ª token - ä¸åº”æ’å…¥é€—å·ï¼ˆtoken æ•°ä¸è¶³ï¼‰
        let action = engine.add_token(TokenInfo::new("ä½ å¥½".to_string(), 0, 600));
        assert_eq!(action, TokenAction::Normal);
    }

    #[test]
    fn test_pause_engine_min_tokens() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // æ·»åŠ  5 ä¸ª tokenï¼ˆå°äº min_tokens: 6ï¼‰
        for i in 0..5 {
            let token = TokenInfo::new(
                format!("token{}", i),
                i * 200,
                i * 700 + 600,
            );
            let action = engine.add_token(token);
            assert_eq!(action, TokenAction::Normal);
        }

        assert_eq!(engine.token_count(), 5);
    }

    #[test]
    fn test_pause_engine_with_pause() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // æ·»åŠ  5 ä¸ªæ­£å¸¸ tokenï¼ˆæ—¶é•¿ 600msï¼‰
        for i in 0..5 {
            let token = TokenInfo::new(
                format!("token{}", i),
                i * 700,
                i * 700 + 600,
            );
            engine.add_token(token);
        }

        // æ·»åŠ ç¬¬ 6 ä¸ª tokenï¼Œæ—¶é•¿å¼‚å¸¸é•¿ï¼ˆåŒ…å«åœé¡¿ï¼‰
        // æ­£å¸¸ 600ms + åœé¡¿ 1700ms = 2300ms
        let long_token = TokenInfo::new(
            "token5".to_string(),
            3500,  // 5 * 700
            5800,  // 3500 + 2300
        );
        engine.add_token(long_token);

        // æ·»åŠ ä¸‹ä¸€ä¸ª token
        // å› ä¸ºä¸Šä¸€ä¸ª token æ—¶é•¿ 2300msï¼Œè¿œè¶…å¹³å‡ 600ms
        // æ¯”ä¾‹ = 2300 / 600 â‰ˆ 3.83 > 3.5ï¼Œåº”è¯¥æ’å…¥é€—å·
        let next_token = TokenInfo::new(
            "next".to_string(),
            5800,
            6400,
        );
        let action = engine.add_token(next_token);
        assert_eq!(action, TokenAction::InsertComma);
    }

    #[test]
    fn test_pause_engine_skip_short_token() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // min_pause_duration_ms = 500ms
        // æ·»åŠ ä¸€ä¸ªæ—¶é•¿ < 500ms çš„ tokenï¼Œåº”è¯¥è¢«è·³è¿‡
        let short_token = TokenInfo::new(" ".to_string(), 0, 41);
        let action = engine.add_token(short_token);
        assert_eq!(action, TokenAction::Skip);

        // éªŒè¯æ²¡æœ‰æ·»åŠ åˆ°å†å²
        assert_eq!(engine.token_count(), 0);
    }

    #[test]
    fn test_pause_engine_min_tokens_between_commas() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // æ·»åŠ  6 ä¸ª token
        for i in 0..6 {
            engine.add_token(TokenInfo::new(
                format!("token{}", i),
                i * 200,
                i * 700 + 600,
            ));
        }

        // è§¦å‘ç¬¬ä¸€ä¸ªé€—å·
        engine.add_token(TokenInfo::new("next".to_string(), 5000, 5600));

        // ç«‹å³å°è¯•è§¦å‘ç¬¬äºŒä¸ªé€—å·ï¼ˆä½† tokens_since_comma < 4ï¼‰
        let token2 = TokenInfo::new("another".to_string(), 7000, 7600);
        let action = engine.add_token(token2);
        assert_eq!(action, TokenAction::Normal);
    }

    #[test]
    fn test_pause_engine_reset() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        engine.add_token(TokenInfo::new("test".to_string(), 0, 600));
        assert_eq!(engine.token_count(), 1);

        engine.reset();
        assert_eq!(engine.token_count(), 0);
    }

    #[test]
    fn test_calculate_avg_duration() {
        let mut engine = PauseEngine::new(StyleProfile::from_preset("Professional"));

        // æ·»åŠ  3 ä¸ª tokenï¼Œæ—¶é•¿åˆ†åˆ«ä¸º 600ms, 700ms, 800msï¼ˆéƒ½ >= 500ms ä¸ä¼šè¢«è·³è¿‡ï¼‰
        engine.add_token(TokenInfo::new("t1".to_string(), 0, 600));
        engine.add_token(TokenInfo::new("t2".to_string(), 600, 1300));
        engine.add_token(TokenInfo::new("t3".to_string(), 1300, 2100));

        let avg = engine.calculate_avg_token_duration();
        assert_eq!(avg, (600 + 700 + 800) / 3); // 700ms
    }

    #[test]
    fn test_token_info_duration() {
        let token = TokenInfo::new("test".to_string(), 100, 350);
        assert_eq!(token.duration_ms(), 250);
    }
}
