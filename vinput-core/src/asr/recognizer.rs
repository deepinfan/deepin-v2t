//! sherpa-onnx åœ¨çº¿è¯†åˆ«å™¨å®‰å…¨å°è£…

use crate::error::{VInputError, VInputResult};
use serde::{Deserialize, Serialize};
use std::ffi::{CStr, CString};
use std::path::Path;
use std::ptr;

// å¼•å…¥ bindgen ç”Ÿæˆçš„ç»‘å®š
include!(concat!(env!("OUT_DIR"), "/sherpa_bindings.rs"));

/// è¯†åˆ«çš„ Token ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct RecognizedToken {
    /// Token æ–‡æœ¬
    pub text: String,
    /// Token å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub start_time_ms: u64,
    /// Token ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub end_time_ms: u64,
    /// ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
    pub confidence: f32,
}

impl RecognizedToken {
    /// Token æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pub fn duration_ms(&self) -> u64 {
        self.end_time_ms.saturating_sub(self.start_time_ms)
    }

    /// è½¬æ¢ä¸º PunctuationEngine çš„ TokenInfo
    pub fn to_token_info(&self) -> crate::punctuation::TokenInfo {
        crate::punctuation::TokenInfo::new(
            self.text.clone(),
            self.start_time_ms,
            self.end_time_ms,
        )
    }
}

/// è¯†åˆ«ç»“æœï¼ˆåŒ…å« Token ä¿¡æ¯ï¼‰
#[derive(Debug, Clone)]
pub struct RecognitionResult {
    /// è¯†åˆ«æ–‡æœ¬
    pub text: String,
    /// Token åˆ—è¡¨ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    pub tokens: Vec<RecognizedToken>,
}

impl RecognitionResult {
    /// åˆ›å»ºç©ºç»“æœ
    pub fn empty() -> Self {
        Self {
            text: String::new(),
            tokens: Vec::new(),
        }
    }

    /// æ˜¯å¦ä¸ºç©º
    pub fn is_empty(&self) -> bool {
        self.text.is_empty()
    }
}

/// åœ¨çº¿è¯†åˆ«å™¨é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OnlineRecognizerConfig {
    /// æ¨¡å‹ç›®å½•è·¯å¾„
    pub model_dir: String,
    /// é‡‡æ ·ç‡ (Hz)
    #[serde(default = "default_sample_rate")]
    pub sample_rate: i32,
    /// ç‰¹å¾ç»´åº¦
    #[serde(default = "default_feat_dim")]
    pub feat_dim: i32,
    /// è§£ç æ–¹æ³• ("greedy_search" æˆ– "modified_beam_search")
    #[serde(default = "default_decoding_method")]
    pub decoding_method: String,
    /// æœ€å¤§æ´»è·ƒè·¯å¾„æ•°
    #[serde(default = "default_max_active_paths")]
    pub max_active_paths: i32,
    /// çƒ­è¯æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    #[serde(default)]
    pub hotwords_file: Option<String>,
    /// çƒ­è¯å¾—åˆ†
    #[serde(default = "default_hotwords_score")]
    pub hotwords_score: f32,
}

// é»˜è®¤å€¼å‡½æ•°
fn default_sample_rate() -> i32 { 16000 }
fn default_feat_dim() -> i32 { 80 }
fn default_decoding_method() -> String { "greedy_search".to_string() }
fn default_max_active_paths() -> i32 { 2 }  // é™ä½åˆ° 2 ä»¥å‡å°‘ CPU å ç”¨ï¼ˆåŸæ¥æ˜¯ 4ï¼‰
fn default_hotwords_score() -> f32 { 1.5 }

impl Default for OnlineRecognizerConfig {
    fn default() -> Self {
        Self {
            model_dir: String::new(),
            sample_rate: 16000,
            feat_dim: 80,
            decoding_method: "greedy_search".to_string(),
            max_active_paths: 2,  // ä¸ serde default ä¿æŒä¸€è‡´
            hotwords_file: None,
            hotwords_score: 1.5,
        }
    }
}

/// åœ¨çº¿è¯†åˆ«å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
pub struct OnlineRecognizer {
    inner: *const SherpaOnnxOnlineRecognizer,
}

// sherpa-onnx çš„ recognizer æ˜¯çº¿ç¨‹å®‰å…¨çš„
unsafe impl Send for OnlineRecognizer {}
unsafe impl Sync for OnlineRecognizer {}

impl OnlineRecognizer {
    /// åˆ›å»ºåœ¨çº¿è¯†åˆ«å™¨
    pub fn new(config: &OnlineRecognizerConfig) -> VInputResult<Self> {
        // éªŒè¯æ¨¡å‹è·¯å¾„
        let model_dir = Path::new(&config.model_dir);
        if !model_dir.exists() {
            return Err(VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: "Model directory not found".to_string(),
            });
        }

        // æ„å»º C API é…ç½®
        // ä½¿ç”¨ Paraformer æ¨¡å‹ï¼ˆINT8 é‡åŒ–ï¼‰
        let encoder_path = model_dir.join("encoder.int8.onnx");
        let decoder_path = model_dir.join("decoder.int8.onnx");
        let tokens_path = model_dir.join("tokens.txt");

        tracing::info!("ğŸ” åŠ è½½ Paraformer æ¨¡å‹:");
        tracing::info!("  Encoder: {:?}", encoder_path);
        tracing::info!("  Decoder: {:?}", decoder_path);
        tracing::info!("  Tokens: {:?}", tokens_path);

        // éªŒè¯æ–‡ä»¶å­˜åœ¨
        if !encoder_path.exists() {
            return Err(VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Encoder æ–‡ä»¶ä¸å­˜åœ¨: {:?}", encoder_path),
            });
        }
        if !decoder_path.exists() {
            return Err(VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Decoder æ–‡ä»¶ä¸å­˜åœ¨: {:?}", decoder_path),
            });
        }
        if !tokens_path.exists() {
            return Err(VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Tokens æ–‡ä»¶ä¸å­˜åœ¨: {:?}", tokens_path),
            });
        }

        // è½¬æ¢ä¸º CString
        let encoder_cstr = CString::new(encoder_path.to_str().unwrap())
            .map_err(|e| VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Invalid path encoding: {}", e),
            })?;
        let decoder_cstr = CString::new(decoder_path.to_str().unwrap())
            .map_err(|e| VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Invalid path encoding: {}", e),
            })?;
        let tokens_cstr = CString::new(tokens_path.to_str().unwrap())
            .map_err(|e| VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: format!("Invalid path encoding: {}", e),
            })?;

        let provider_cstr = CString::new("cpu").unwrap();
        let decoding_method_cstr = CString::new(config.decoding_method.as_str()).unwrap();
        let hotwords_cstr = config
            .hotwords_file
            .as_ref()
            .map(|s| CString::new(s.as_str()).ok())
            .flatten();

        // æ„å»º Paraformer é…ç½®ç»“æ„ä½“
        let paraformer_config = SherpaOnnxOnlineParaformerModelConfig {
            encoder: encoder_cstr.as_ptr(),
            decoder: decoder_cstr.as_ptr(),
        };

        let model_config = SherpaOnnxOnlineModelConfig {
            transducer: unsafe { std::mem::zeroed() },
            paraformer: paraformer_config,
            zipformer2_ctc: unsafe { std::mem::zeroed() },
            tokens: tokens_cstr.as_ptr(),
            num_threads: 1,  // é™ä½åˆ° 1 ä»¥æœ€å°åŒ– CPU å ç”¨
            provider: provider_cstr.as_ptr(),
            debug: 0,
            model_type: ptr::null(),
            modeling_unit: ptr::null(),
            bpe_vocab: ptr::null(),
            tokens_buf: ptr::null(),
            tokens_buf_size: 0,
            nemo_ctc: unsafe { std::mem::zeroed() },
            t_one_ctc: unsafe { std::mem::zeroed() },
        };

        let recognizer_config = SherpaOnnxOnlineRecognizerConfig {
            feat_config: SherpaOnnxFeatureConfig {
                sample_rate: config.sample_rate,
                feature_dim: config.feat_dim,
            },
            model_config,
            decoding_method: decoding_method_cstr.as_ptr(),
            max_active_paths: config.max_active_paths,
            enable_endpoint: 1,
            rule1_min_trailing_silence: 2.4,
            rule2_min_trailing_silence: 1.2,
            rule3_min_utterance_length: 20.0,
            hotwords_file: hotwords_cstr
                .as_ref()
                .map(|s| s.as_ptr())
                .unwrap_or(ptr::null()),
            hotwords_score: config.hotwords_score,
            ctc_fst_decoder_config: unsafe { std::mem::zeroed() },
            rule_fsts: ptr::null(),
            rule_fars: ptr::null(),
            blank_penalty: 0.0,  // Paraformer ä¸ä½¿ç”¨ blank_penalty
            hotwords_buf: ptr::null(),
            hotwords_buf_size: 0,
            hr: unsafe { std::mem::zeroed() },
        };

        // è°ƒç”¨ C API åˆ›å»ºè¯†åˆ«å™¨
        let recognizer = unsafe { SherpaOnnxCreateOnlineRecognizer(&recognizer_config) };

        if recognizer.is_null() {
            return Err(VInputError::ModelLoad {
                path: config.model_dir.clone(),
                reason: "Failed to create recognizer".to_string(),
            });
        }

        Ok(Self { inner: recognizer })
    }

    /// åˆ›å»ºæ–°çš„è¯†åˆ«æµ
    pub fn create_stream(&self) -> VInputResult<OnlineStream<'_>> {
        let stream = unsafe { SherpaOnnxCreateOnlineStream(self.inner) };

        if stream.is_null() {
            return Err(VInputError::AsrInference(
                "Failed to create stream".to_string(),
            ));
        }

        Ok(OnlineStream {
            inner: stream,
            _recognizer: std::marker::PhantomData,
        })
    }

    /// è·å–åŸå§‹æŒ‡é’ˆï¼ˆä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼‰
    pub(crate) fn as_ptr(&self) -> *const SherpaOnnxOnlineRecognizer {
        self.inner
    }
}

impl Drop for OnlineRecognizer {
    fn drop(&mut self) {
        if !self.inner.is_null() {
            unsafe {
                SherpaOnnxDestroyOnlineRecognizer(self.inner);
            }
        }
    }
}

/// åœ¨çº¿è¯†åˆ«æµ
pub struct OnlineStream<'a> {
    inner: *const SherpaOnnxOnlineStream,
    _recognizer: std::marker::PhantomData<&'a OnlineRecognizer>,
}

// sherpa-onnx çš„ stream æ˜¯çº¿ç¨‹å®‰å…¨çš„
// è™½ç„¶å®ƒæ˜¯è£¸æŒ‡é’ˆï¼Œä½† C åº“ä¿è¯äº†çº¿ç¨‹å®‰å…¨æ€§
unsafe impl Send for OnlineStream<'_> {}
unsafe impl Sync for OnlineStream<'_> {}

impl<'a> OnlineStream<'a> {
    /// è¾“å…¥éŸ³é¢‘æ•°æ®ï¼ˆ16kHz, å•å£°é“, f32 æ ¼å¼ï¼‰
    pub fn accept_waveform(&mut self, samples: &[f32], sample_rate: i32) {
        unsafe {
            SherpaOnnxOnlineStreamAcceptWaveform(
                self.inner,
                sample_rate,
                samples.as_ptr(),
                samples.len() as i32,
            );
        }
    }

    /// æ£€æŸ¥æµæ˜¯å¦å‡†å¤‡å¥½è§£ç 
    pub fn is_ready(&self, recognizer: &OnlineRecognizer) -> bool {
        unsafe { SherpaOnnxIsOnlineStreamReady(recognizer.as_ptr(), self.inner) != 0 }
    }

    /// è§£ç å½“å‰æµ
    pub fn decode(&mut self, recognizer: &OnlineRecognizer) {
        unsafe {
            SherpaOnnxDecodeOnlineStream(recognizer.as_ptr(), self.inner);
        }
    }

    /// è·å–è¯†åˆ«ç»“æœï¼ˆä»…æ–‡æœ¬ï¼Œä¸æå– token åˆ—è¡¨ï¼Œæ•ˆç‡æ›´é«˜ï¼‰
    ///
    /// ç”¨äºæµå¼è¯†åˆ«è¿‡ç¨‹ä¸­é¢‘ç¹æŸ¥è¯¢å½“å‰éƒ¨åˆ†ç»“æœ
    pub fn get_result(&self, recognizer: &OnlineRecognizer) -> String {
        unsafe {
            let result_ptr = SherpaOnnxGetOnlineStreamResult(recognizer.as_ptr(), self.inner);
            if result_ptr.is_null() {
                return String::new();
            }

            let text_ptr = (*result_ptr).text;
            let text = if !text_ptr.is_null() {
                CStr::from_ptr(text_ptr)
                    .to_string_lossy()
                    .into_owned()
            } else {
                String::new()
            };

            SherpaOnnxDestroyOnlineRecognizerResult(result_ptr);
            text
        }
    }

    /// è·å–è¯¦ç»†è¯†åˆ«ç»“æœï¼ˆåŒ…å« Token å’Œæ—¶é—´æˆ³ï¼‰
    pub fn get_detailed_result(&self, recognizer: &OnlineRecognizer) -> RecognitionResult {
        unsafe {
            let result_ptr = SherpaOnnxGetOnlineStreamResult(recognizer.as_ptr(), self.inner);
            if result_ptr.is_null() {
                tracing::warn!("âš ï¸  Sherpa-ONNX è¿”å›ç©ºæŒ‡é’ˆ");
                return RecognitionResult::empty();
            }

            let text_ptr = (*result_ptr).text;
            let text = if !text_ptr.is_null() {
                CStr::from_ptr(text_ptr)
                    .to_string_lossy()
                    .into_owned()
            } else {
                String::new()
            };

            // æå– Tokens å’Œæ—¶é—´æˆ³
            let mut tokens = Vec::new();
            let count = (*result_ptr).count as usize;

            tracing::debug!("ğŸ” Sherpa-ONNX åŸå§‹ç»“æœ:");
            tracing::debug!("  - text: '{}'", text);
            tracing::debug!("  - count: {}", count);
            tracing::debug!("  - tokens_arr.is_null(): {}", (*result_ptr).tokens_arr.is_null());
            tracing::debug!("  - timestamps.is_null(): {}", (*result_ptr).timestamps.is_null());

            // Paraformer æ¨¡å‹ä¸æä¾› timestampsï¼Œä½†æä¾› tokens_arr
            if count > 0 && !(*result_ptr).tokens_arr.is_null() {
                let tokens_arr = std::slice::from_raw_parts((*result_ptr).tokens_arr, count);

                // æ£€æŸ¥æ˜¯å¦æœ‰ timestampsï¼ˆTransducer æœ‰ï¼ŒParaformer æ²¡æœ‰ï¼‰
                let has_timestamps = !(*result_ptr).timestamps.is_null();
                let timestamps = if has_timestamps {
                    Some(std::slice::from_raw_parts((*result_ptr).timestamps, count))
                } else {
                    None
                };

                if has_timestamps {
                    tracing::debug!("ğŸ“ Sherpa-ONNX åŸå§‹ timestamps (ç§’): {:?}",
                        timestamps.unwrap().iter().take(count.min(20)).collect::<Vec<_>>());
                } else {
                    tracing::debug!("âš ï¸  Paraformer æ¨¡å‹ä¸æä¾› timestampsï¼Œä½¿ç”¨ä¼°ç®—æ—¶é—´");
                }

                for i in 0..count {
                    if !tokens_arr[i].is_null() {
                        let token_text = CStr::from_ptr(tokens_arr[i])
                            .to_string_lossy()
                            .into_owned();

                        // è®¡ç®—æ—¶é—´æˆ³
                        let (start_time_ms, end_time_ms) = if let Some(ts) = timestamps {
                            // Transducer: ä½¿ç”¨çœŸå® timestamps
                            let start_time_s = ts[i];
                            let end_time_s = if i + 1 < count {
                                ts[i + 1]
                            } else {
                                start_time_s + 0.2
                            };
                            ((start_time_s * 1000.0) as u64, (end_time_s * 1000.0) as u64)
                        } else {
                            // Paraformer: ä¼°ç®—æ—¶é—´ï¼ˆæ ¹æ® token ç±»å‹åŠ¨æ€è°ƒæ•´ï¼‰
                            let char_duration_ms = Self::estimate_token_duration(&token_text);
                            let start = if i == 0 {
                                0
                            } else {
                                // ç´¯åŠ å‰é¢æ‰€æœ‰ tokens çš„ä¼°ç®—æ—¶é•¿
                                (0..i).map(|idx| {
                                    if !tokens_arr[idx].is_null() {
                                        let prev_text = CStr::from_ptr(tokens_arr[idx])
                                            .to_string_lossy()
                                            .into_owned();
                                        Self::estimate_token_duration(&prev_text)
                                    } else {
                                        0
                                    }
                                }).sum()
                            };
                            let end = start + char_duration_ms;
                            (start, end)
                        };

                        tokens.push(RecognizedToken {
                            text: token_text,
                            start_time_ms,
                            end_time_ms,
                            confidence: 1.0,
                        });
                    }
                }

                tracing::debug!("âœ… æå–äº† {} ä¸ªåŸå§‹ tokens", tokens.len());

                // åˆå¹¶ BPE tokensï¼ˆå¤„ç† @@ æ ‡è®°ï¼‰
                tokens = Self::merge_bpe_tokens(tokens);
                tracing::debug!("âœ… BPE åˆå¹¶å: {} ä¸ª tokens", tokens.len());
            }

            let result = RecognitionResult {
                text,
                tokens,
            };

            SherpaOnnxDestroyOnlineRecognizerResult(result_ptr);
            result
        }
    }

    /// åˆå¹¶ BPE tokensï¼ˆå¤„ç† @@ æ ‡è®°ï¼‰
    ///
    /// ä¾‹å¦‚: ["ban@@", "k", "up"] -> ["backup"]
    fn merge_bpe_tokens(tokens: Vec<RecognizedToken>) -> Vec<RecognizedToken> {
        let mut merged = Vec::new();
        let mut i = 0;

        while i < tokens.len() {
            let token = &tokens[i];

            // æ£€æŸ¥æ˜¯å¦ä»¥ @@ ç»“å°¾ï¼ˆéœ€è¦åˆå¹¶ï¼‰
            if token.text.ends_with("@@") {
                // å¼€å§‹åˆå¹¶
                let mut merged_text = token.text.trim_end_matches("@@").to_string();
                let start_time = token.start_time_ms;
                let mut end_time = token.end_time_ms;
                let mut j = i + 1;

                // ç»§ç»­åˆå¹¶åç»­ tokensï¼Œç›´åˆ°é‡åˆ°ä¸ä»¥ @@ ç»“å°¾çš„ token
                while j < tokens.len() {
                    let next_token = &tokens[j];
                    if next_token.text.ends_with("@@") {
                        merged_text.push_str(next_token.text.trim_end_matches("@@"));
                        end_time = next_token.end_time_ms;
                        j += 1;
                    } else {
                        // æœ€åä¸€ä¸ª token
                        merged_text.push_str(&next_token.text);
                        end_time = next_token.end_time_ms;
                        j += 1;
                        break;
                    }
                }

                tracing::debug!("  ğŸ”— BPE åˆå¹¶: {} tokens -> '{}' ({}ms - {}ms, duration={}ms)",
                    j - i, merged_text, start_time, end_time, end_time - start_time);

                merged.push(RecognizedToken {
                    text: merged_text,
                    start_time_ms: start_time,
                    end_time_ms: end_time,
                    confidence: token.confidence,
                });

                i = j;
            } else {
                // ä¸éœ€è¦åˆå¹¶ï¼Œç›´æ¥æ·»åŠ 
                merged.push(token.clone());
                i += 1;
            }
        }

        merged
    }

    /// ä¼°ç®— token çš„å‘éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    ///
    /// æ ¹æ® token ç±»å‹ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€BPE ç‰‡æ®µï¼‰åŠ¨æ€è°ƒæ•´
    fn estimate_token_duration(token_text: &str) -> u64 {
        // BPE ç‰‡æ®µï¼ˆä»¥ @@ ç»“å°¾ï¼‰ï¼šè¾ƒçŸ­
        if token_text.ends_with("@@") {
            return 80;  // BPE å­è¯ç‰‡æ®µé€šå¸¸å¾ˆçŸ­
        }

        // æ£€æŸ¥æ˜¯å¦ä¸ºçº¯è‹±æ–‡/æ•°å­—
        let is_ascii = token_text.chars().all(|c| c.is_ascii());

        if is_ascii {
            // è‹±æ–‡å•è¯ï¼šæ ¹æ®é•¿åº¦ä¼°ç®—
            let len = token_text.len() as u64;
            if len <= 2 {
                100  // çŸ­å•è¯å¦‚ "I", "is", "to"
            } else if len <= 5 {
                150  // ä¸­ç­‰å•è¯å¦‚ "hello", "world"
            } else {
                200  // é•¿å•è¯å¦‚ "backup", "system"
            }
        } else {
            // ä¸­æ–‡å­—ç¬¦ï¼šæ¯ä¸ªå­—ç¬¦çº¦ 200ms
            let char_count = token_text.chars().count() as u64;
            char_count * 200
        }
    }

    /// æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ç«¯ç‚¹
    pub fn is_endpoint(&self, recognizer: &OnlineRecognizer) -> bool {
        unsafe { SherpaOnnxOnlineStreamIsEndpoint(recognizer.as_ptr(), self.inner) != 0 }
    }

    /// é‡ç½®æµçŠ¶æ€
    pub fn reset(&mut self, recognizer: &OnlineRecognizer) {
        unsafe {
            SherpaOnnxOnlineStreamReset(recognizer.as_ptr(), self.inner);
        }
    }

    /// æ ‡è®°è¾“å…¥ç»“æŸ
    pub fn input_finished(&mut self) {
        unsafe {
            SherpaOnnxOnlineStreamInputFinished(self.inner);
        }
    }
}

impl<'a> Drop for OnlineStream<'a> {
    fn drop(&mut self) {
        if !self.inner.is_null() {
            unsafe {
                SherpaOnnxDestroyOnlineStream(self.inner);
            }
        }
    }
}
