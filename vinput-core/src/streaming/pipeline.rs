//! Streaming Pipeline - VAD-ASR æµå¼è¯†åˆ«ç®¡é“
//!
//! å°† VAD æ£€æµ‹ç»“æœä¸ ASR è¯†åˆ«å™¨è¿æ¥ï¼Œå®ç°ç«¯åˆ°ç«¯çš„æµå¼è¯­éŸ³è¯†åˆ«

use crate::asr::{OnlineRecognizer, OnlineRecognizerConfig, OnlineStream, RecognitionResult};
use crate::error::VInputResult;
use crate::punctuation::{PunctuationEngine, StyleProfile};
use crate::vad::{VadConfig, VadManager, VadState};
use std::time::Instant;

/// æµå¼ç®¡é“é…ç½®
#[derive(Debug, Clone)]
pub struct StreamingConfig {
    /// VAD é…ç½®
    pub vad_config: VadConfig,
    /// ASR é…ç½®
    pub asr_config: OnlineRecognizerConfig,
    /// æ ‡ç‚¹é£æ ¼é…ç½®
    pub punctuation_profile: StyleProfile,
    /// æœ€å¤§é™éŸ³ç­‰å¾…æ—¶é—´ (ms) - è¶…è¿‡æ­¤æ—¶é—´åå¼ºåˆ¶ç»“æŸè¯†åˆ«
    pub max_silence_duration_ms: u64,
    /// å¯ç”¨ç«¯ç‚¹æ£€æµ‹
    pub enable_endpoint_detection: bool,
}

impl Default for StreamingConfig {
    fn default() -> Self {
        Self {
            vad_config: VadConfig::push_to_talk_default(),
            asr_config: OnlineRecognizerConfig::default(),
            punctuation_profile: StyleProfile::default(),
            max_silence_duration_ms: 3000,
            enable_endpoint_detection: true,
        }
    }
}

/// ç®¡é“çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PipelineState {
    /// ç©ºé—²çŠ¶æ€ï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥
    Idle,
    /// æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ­£åœ¨è¯†åˆ«
    Recognizing,
    /// è¯†åˆ«å®Œæˆï¼Œç­‰å¾…é‡ç½®
    Completed,
}

/// æµå¼è¯†åˆ«ç»“æœ
#[derive(Debug, Clone)]
pub struct StreamingResult {
    /// å½“å‰è¯†åˆ«çš„éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ›´æ–°ï¼‰
    pub partial_result: String,
    /// æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
    pub is_final: bool,
    /// VAD çŠ¶æ€
    pub vad_state: VadState,
    /// ç®¡é“çŠ¶æ€
    pub pipeline_state: PipelineState,
    /// è¯­éŸ³æ¦‚ç‡
    pub speech_prob: f32,
    /// è‡ªä¸Šæ¬¡è¯­éŸ³å¼€å§‹ä»¥æ¥çš„æŒç»­æ—¶é—´ (ms)
    pub duration_ms: u64,
}

/// VAD-ASR æµå¼è¯†åˆ«ç®¡é“
pub struct StreamingPipeline {
    config: StreamingConfig,
    vad_manager: VadManager,
    asr_recognizer: OnlineRecognizer,
    asr_stream: Option<OnlineStream<'static>>,
    punctuation_engine: PunctuationEngine,
    pipeline_state: PipelineState,

    /// è¯­éŸ³å¼€å§‹æ—¶é—´
    speech_start_time: Option<Instant>,
    /// æœ€åä¸€æ¬¡è¯­éŸ³æ´»åŠ¨æ—¶é—´
    last_speech_time: Option<Instant>,

    /// ç´¯ç§¯çš„éŸ³é¢‘å¸§æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    total_frames: u64,
    /// é€å…¥ ASR çš„éŸ³é¢‘å¸§æ•°
    asr_frames: u64,
    /// VAD é™éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    vad_silence_ms: u64,
}

impl StreamingPipeline {
    /// åˆ›å»ºæ–°çš„æµå¼ç®¡é“
    pub fn new(config: StreamingConfig) -> VInputResult<Self> {
        tracing::info!("ğŸ“ StreamingPipeline::new - æ¥æ”¶åˆ°çš„æ ‡ç‚¹é…ç½®: pause_ratio={}, min_tokens={}",
            config.punctuation_profile.streaming_pause_ratio,
            config.punctuation_profile.streaming_min_tokens
        );

        let vad_manager = VadManager::new(config.vad_config.clone())?;
        let asr_recognizer = OnlineRecognizer::new(&config.asr_config)?;
        let punctuation_engine = PunctuationEngine::new(config.punctuation_profile.clone());

        Ok(Self {
            config,
            vad_manager,
            asr_recognizer,
            punctuation_engine,
            asr_stream: None,
            pipeline_state: PipelineState::Idle,
            speech_start_time: None,
            last_speech_time: None,
            total_frames: 0,
            asr_frames: 0,
            vad_silence_ms: 0,
        })
    }

    /// å¤„ç†éŸ³é¢‘å¸§
    ///
    /// # å‚æ•°
    /// - `samples`: éŸ³é¢‘æ ·æœ¬ (f32, [-1.0, 1.0])
    ///   - å¯¹äº 16kHz: 512 samples (32ms)
    ///
    /// # è¿”å›
    /// - `StreamingResult`: æµå¼è¯†åˆ«ç»“æœ
    pub fn process(&mut self, samples: &[f32]) -> VInputResult<StreamingResult> {
        self.total_frames += 1;

        // 1. VAD å¤„ç†
        let vad_result = self.vad_manager.process(samples)?;
        let now = Instant::now();

        // 2. æ ¹æ® VAD çŠ¶æ€ç®¡ç† ASR æµ
        match (self.pipeline_state, vad_result.state) {
            // ä»ç©ºé—²çŠ¶æ€æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
            (PipelineState::Idle, VadState::Speech) if vad_result.state_changed => {
                tracing::info!("Pipeline: Speech detected, starting ASR");

                // åˆ›å»ºæ–°çš„ ASR æµ
                let mut stream = self.asr_recognizer.create_stream()?;

                // æ³¨å…¥ Pre-roll éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
                if let Some(pre_roll_audio) = &vad_result.pre_roll_audio {
                    if !pre_roll_audio.is_empty() {
                        stream.accept_waveform(
                            pre_roll_audio,
                            self.config.vad_config.silero.sample_rate as i32,
                        );
                        self.asr_frames += 1;
                        tracing::debug!(
                            "Pipeline: Injected {} pre-roll samples",
                            pre_roll_audio.len()
                        );
                    }
                }

                // å­˜å‚¨æµçš„ç”Ÿå‘½å‘¨æœŸï¼ˆéœ€è¦ unsafe transmute æ¥ç»•è¿‡ç”Ÿå‘½å‘¨æœŸæ£€æŸ¥ï¼‰
                // å®‰å…¨æ€§ï¼šstream çš„ç”Ÿå‘½å‘¨æœŸç”± self.asr_stream ç®¡ç†ï¼Œåœ¨ reset æ—¶ä¼šè¢«é”€æ¯
                let stream_static: OnlineStream<'static> = unsafe {
                    std::mem::transmute(stream)
                };
                self.asr_stream = Some(stream_static);

                self.pipeline_state = PipelineState::Recognizing;
                self.speech_start_time = Some(now);
                self.last_speech_time = Some(now);
            }

            // è¯†åˆ«ä¸­ï¼Œç»§ç»­é€å…¥éŸ³é¢‘
            (PipelineState::Recognizing, VadState::Speech | VadState::SpeechCandidate) => {
                if self.asr_stream.is_some() {
                    let samples_vec = samples.to_vec();
                    self.feed_audio_to_asr_internal(&samples_vec)?;
                    self.last_speech_time = Some(now);
                }
            }

            // æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
            (PipelineState::Recognizing, VadState::Silence) if vad_result.state_changed => {
                // è®¡ç®—é™éŸ³æ—¶é•¿
                if let Some(last_time) = self.last_speech_time {
                    self.vad_silence_ms = now.duration_since(last_time).as_millis() as u64;
                }

                tracing::info!("Pipeline: Speech ended (silence: {}ms), finalizing ASR", self.vad_silence_ms);

                if let Some(stream) = &mut self.asr_stream {
                    // æ ‡è®°è¾“å…¥ç»“æŸ
                    stream.input_finished();

                    // æœ€åä¸€æ¬¡è§£ç 
                    if stream.is_ready(&self.asr_recognizer) {
                        stream.decode(&self.asr_recognizer);
                    }
                }

                self.pipeline_state = PipelineState::Completed;
            }

            // è¯†åˆ«ä¸­ï¼Œæ£€æŸ¥é™éŸ³è¶…æ—¶
            (PipelineState::Recognizing, VadState::SilenceCandidate) => {
                if self.asr_stream.is_some() {
                    let samples_vec = samples.to_vec();
                    self.feed_audio_to_asr_internal(&samples_vec)?;
                }

                // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é™éŸ³æ—¶é—´
                if let Some(last_time) = self.last_speech_time {
                    let silence_duration = now.duration_since(last_time);
                    if silence_duration.as_millis() as u64 > self.config.max_silence_duration_ms {
                        tracing::warn!(
                            "Pipeline: Max silence duration exceeded ({:?}), finalizing",
                            silence_duration
                        );

                        if let Some(stream) = &mut self.asr_stream {
                            stream.input_finished();
                        }
                        self.pipeline_state = PipelineState::Completed;
                    }
                }
            }

            _ => {
                // å…¶ä»–çŠ¶æ€ç»„åˆï¼Œä¸åšå¤„ç†
            }
        }

        // 3. æ‰§è¡Œ ASR è§£ç ï¼ˆå¦‚æœæµå‡†å¤‡å¥½ï¼‰
        if self.pipeline_state == PipelineState::Recognizing {
            if let Some(stream) = &mut self.asr_stream {
                if stream.is_ready(&self.asr_recognizer) {
                    stream.decode(&self.asr_recognizer);
                }

                // æ£€æŸ¥ç«¯ç‚¹æ£€æµ‹
                if self.config.enable_endpoint_detection && stream.is_endpoint(&self.asr_recognizer) {
                    tracing::info!("Pipeline: Endpoint detected by ASR");
                    stream.input_finished();
                    self.pipeline_state = PipelineState::Completed;
                }
            }
        }

        // 4. è·å–è¯†åˆ«ç»“æœ
        let partial_result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        let is_final = self.pipeline_state == PipelineState::Completed;

        let duration_ms = self.speech_start_time
            .map(|start| now.duration_since(start).as_millis() as u64)
            .unwrap_or(0);

        Ok(StreamingResult {
            partial_result,
            is_final,
            vad_state: vad_result.state,
            pipeline_state: self.pipeline_state,
            speech_prob: vad_result.speech_prob,
            duration_ms,
        })
    }

    /// å°†éŸ³é¢‘æ•°æ®é€å…¥ ASRï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œé¿å…å€Ÿç”¨å†²çªï¼‰
    fn feed_audio_to_asr_internal(&mut self, samples: &[f32]) -> VInputResult<()> {
        if let Some(stream) = &mut self.asr_stream {
            stream.accept_waveform(
                samples,
                self.config.vad_config.silero.sample_rate as i32,
            );
            self.asr_frames += 1;
        }
        Ok(())
    }

    /// é‡ç½®ç®¡é“çŠ¶æ€
    pub fn reset(&mut self) -> VInputResult<()> {
        tracing::debug!("Pipeline: Resetting");

        // é”€æ¯ ASR æµ
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }

        // é‡ç½® VAD
        self.vad_manager.reset();

        // é‡ç½®æ ‡ç‚¹å¼•æ“
        self.punctuation_engine.reset_sentence();

        // é‡ç½®çŠ¶æ€
        self.pipeline_state = PipelineState::Idle;
        self.speech_start_time = None;
        self.last_speech_time = None;
        self.vad_silence_ms = 0;

        Ok(())
    }

    /// å¼ºåˆ¶è®¾ç½® VAD çŠ¶æ€ï¼ˆç”¨äº PushToTalk æ¨¡å¼ï¼‰
    pub fn force_vad_state(&mut self, state: VadState) {
        self.vad_manager.force_state(state);
    }

    /// è·å–å½“å‰ç®¡é“çŠ¶æ€
    pub fn pipeline_state(&self) -> PipelineState {
        self.pipeline_state
    }

    /// è·å– VAD çŠ¶æ€
    pub fn vad_state(&self) -> VadState {
        self.vad_manager.state()
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    pub fn stats(&self) -> PipelineStats {
        PipelineStats {
            total_frames: self.total_frames,
            asr_frames: self.asr_frames,
            speech_duration_ms: self.speech_start_time
                .map(|start| Instant::now().duration_since(start).as_millis() as u64)
                .unwrap_or(0),
        }
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆå¸¦æ ‡ç‚¹ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result_with_punctuation(&mut self) -> String {
        let result = if let Some(stream) = &self.asr_stream {
            // è·å–è¯¦ç»†ç»“æœï¼ˆåŒ…å« Token å’Œæ—¶é—´æˆ³ï¼‰
            let detailed_result = stream.get_detailed_result(&self.asr_recognizer);

            tracing::debug!("ğŸ“Š è¯†åˆ«ç»“æœè¯¦æƒ…: text='{}', token_count={}",
                detailed_result.text, detailed_result.tokens.len());

            if detailed_result.is_empty() {
                tracing::warn!("âš ï¸  è¯†åˆ«ç»“æœä¸ºç©º");
                String::new()
            } else {
                // æ‰“å°æ‰€æœ‰ Token ä¿¡æ¯
                for (i, token) in detailed_result.tokens.iter().enumerate() {
                    tracing::debug!("  Token[{}]: '{}' ({}ms - {}ms, duration={}ms)",
                        i, token.text, token.start_time_ms, token.end_time_ms, token.duration_ms());
                }

                // å¤„ç†æ¯ä¸ª Tokenï¼Œæ·»åŠ æ ‡ç‚¹
                let mut final_text = String::new();

                for token in &detailed_result.tokens {
                    // è½¬æ¢ä¸º TokenInfo
                    let token_info = token.to_token_info();

                    // å¤„ç† Tokenï¼ˆå¯èƒ½åœ¨å‰é¢æ·»åŠ é€—å·ï¼‰
                    if let Some(processed_token) = self.punctuation_engine.process_token(token_info) {
                        tracing::debug!("  å¤„ç† Token: '{}' -> '{}'", token.text, processed_token);
                        final_text.push_str(&processed_token);
                    } else {
                        tracing::debug!("  Token è¢«è¿‡æ»¤: '{}'", token.text);
                    }
                }

                // æ£€æµ‹ VAD èƒ½é‡å˜åŒ–ï¼ˆç”¨äºé—®å·æ£€æµ‹ï¼‰
                // TODO: å®ç°çœŸå®çš„èƒ½é‡æ£€æµ‹ï¼Œç›®å‰æš‚æ—¶ç”¨ false
                let energy_rising = false;

                tracing::debug!("ğŸ”š å‡†å¤‡æ·»åŠ å¥å°¾æ ‡ç‚¹: vad_silence_ms={}, energy_rising={}",
                    self.vad_silence_ms, energy_rising);

                // æ·»åŠ å¥å°¾æ ‡ç‚¹
                let ending = self.punctuation_engine.finalize_sentence(
                    self.vad_silence_ms,
                    energy_rising,
                );

                tracing::debug!("  å¥å°¾æ ‡ç‚¹: '{}'", ending);
                final_text.push_str(&ending);

                tracing::info!("âœ… æ ‡ç‚¹å¤„ç†å®Œæˆ: '{}'", final_text);
                final_text
            }
        } else {
            tracing::warn!("âš ï¸  ASR æµä¸ºç©º");
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆä¸å¸¦æ ‡ç‚¹ï¼ŒåŸå§‹æ–‡æœ¬ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result(&mut self) -> String {
        let result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }
}

impl Drop for StreamingPipeline {
    fn drop(&mut self) {
        // ç¡®ä¿ ASR æµåœ¨ç®¡é“é”€æ¯å‰è¢«æ¸…ç†
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }
    }
}

/// ç®¡é“ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct PipelineStats {
    /// å¤„ç†çš„æ€»å¸§æ•°
    pub total_frames: u64,
    /// é€å…¥ ASR çš„å¸§æ•°
    pub asr_frames: u64,
    /// è¯­éŸ³æŒç»­æ—¶é—´ (ms)
    pub speech_duration_ms: u64,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_streaming_config_default() {
        let config = StreamingConfig::default();
        assert_eq!(config.max_silence_duration_ms, 3000);
        assert!(config.enable_endpoint_detection);
    }

    #[test]
    fn test_pipeline_state_transitions() {
        assert_eq!(PipelineState::Idle, PipelineState::Idle);
        assert_ne!(PipelineState::Idle, PipelineState::Recognizing);
    }
}
