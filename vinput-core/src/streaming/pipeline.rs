//! Streaming Pipeline - VAD-ASR æµå¼è¯†åˆ«ç®¡é“
//!
//! å°† VAD æ£€æµ‹ç»“æœä¸ ASR è¯†åˆ«å™¨è¿æ¥ï¼Œå®ç°ç«¯åˆ°ç«¯çš„æµå¼è¯­éŸ³è¯†åˆ«

use crate::asr::{OnlineRecognizer, OnlineRecognizerConfig, OnlineStream};
use crate::endpointing::{EndpointDetector, EndpointDetectorConfig, EndpointResult};
use crate::error::VInputResult;
use crate::punctuation::{PunctuationEngine, StyleProfile};
use crate::vad::{VadConfig, VadManager, VadState};
use std::time::Instant;

/// æµå¼ç®¡é“é…ç½®
#[derive(Debug, Clone)]
pub struct StreamingConfig {
    /// VAD é…ç½®
    pub vad_config: VadConfig,
    /// ASR é…ç½®
    pub asr_config: OnlineRecognizerConfig,
    /// æ ‡ç‚¹é£æ ¼é…ç½®
    pub punctuation_profile: StyleProfile,
    /// ç«¯ç‚¹æ£€æµ‹é…ç½®
    pub endpoint_config: EndpointDetectorConfig,
}

impl Default for StreamingConfig {
    fn default() -> Self {
        Self {
            vad_config: VadConfig::push_to_talk_default(),
            asr_config: OnlineRecognizerConfig::default(),
            punctuation_profile: StyleProfile::default(),
            endpoint_config: EndpointDetectorConfig::default(),
        }
    }
}

/// ç®¡é“çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PipelineState {
    /// ç©ºé—²çŠ¶æ€ï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥
    Idle,
    /// æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ­£åœ¨è¯†åˆ«
    Recognizing,
    /// è¯†åˆ«å®Œæˆï¼Œç­‰å¾…é‡ç½®
    Completed,
}

/// æµå¼è¯†åˆ«ç»“æœ
#[derive(Debug, Clone)]
pub struct StreamingResult {
    /// å½“å‰è¯†åˆ«çš„éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ›´æ–°ï¼‰
    pub partial_result: String,
    /// ç¨³å®šçš„æ–‡æœ¬ï¼ˆå¯ä»¥ç«‹å³ä¸Šå±ï¼‰
    pub stable_text: String,
    /// ä¸ç¨³å®šçš„æ–‡æœ¬ï¼ˆä¿ç•™åœ¨ Preeditï¼‰
    pub unstable_text: String,
    /// æ˜¯å¦åº”è¯¥æ·»åŠ é€—å·ï¼ˆæ£€æµ‹åˆ°åœé¡¿ï¼‰
    pub should_add_comma: bool,
    /// æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
    pub is_final: bool,
    /// VAD çŠ¶æ€
    pub vad_state: VadState,
    /// ç®¡é“çŠ¶æ€
    pub pipeline_state: PipelineState,
    /// è¯­éŸ³æ¦‚ç‡
    pub speech_prob: f32,
    /// è‡ªä¸Šæ¬¡è¯­éŸ³å¼€å§‹ä»¥æ¥çš„æŒç»­æ—¶é—´ (ms)
    pub duration_ms: u64,
}

/// VAD-ASR æµå¼è¯†åˆ«ç®¡é“
pub struct StreamingPipeline {
    config: StreamingConfig,
    vad_manager: VadManager,
    asr_recognizer: OnlineRecognizer,
    asr_stream: Option<OnlineStream<'static>>,
    punctuation_engine: PunctuationEngine,
    endpoint_detector: EndpointDetector,
    pipeline_state: PipelineState,

    /// è¯­éŸ³å¼€å§‹æ—¶é—´
    speech_start_time: Option<Instant>,

    /// ASR endpoint æ£€æµ‹åˆ°åçš„ç¼“å†²å¸§æ•°ï¼ˆè¿˜å‰©å¤šå°‘å¸§æ‰çœŸæ­£æäº¤ï¼‰
    /// 0 è¡¨ç¤ºæ²¡æœ‰å¾…æäº¤çš„ endpointï¼Œ> 0 è¡¨ç¤ºä»åœ¨ç¼“å†²æœŸï¼ˆç»§ç»­å–‚éŸ³é¢‘ï¼‰
    asr_endpoint_grace_remaining: u32,

    /// ç´¯ç§¯çš„éŸ³é¢‘å¸§æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    total_frames: u64,
    /// é€å…¥ ASR çš„éŸ³é¢‘å¸§æ•°
    asr_frames: u64,
}

impl StreamingPipeline {
    /// åˆ›å»ºæ–°çš„æµå¼ç®¡é“
    pub fn new(config: StreamingConfig) -> VInputResult<Self> {
        tracing::info!("ğŸ“ StreamingPipeline::new - æ¥æ”¶åˆ°çš„æ ‡ç‚¹é…ç½®: pause_ratio={}, min_tokens={}",
            config.punctuation_profile.streaming_pause_ratio,
            config.punctuation_profile.streaming_min_tokens
        );
        tracing::info!("ğŸ¯ ç«¯ç‚¹æ£€æµ‹é…ç½®: trailing_silence={}ms, min_speech={}ms",
            config.endpoint_config.trailing_silence_ms,
            config.endpoint_config.min_speech_duration_ms
        );

        let vad_manager = VadManager::new(config.vad_config.clone())?;
        let asr_recognizer = OnlineRecognizer::new(&config.asr_config)?;
        let punctuation_engine = PunctuationEngine::new(config.punctuation_profile.clone());
        let endpoint_detector = EndpointDetector::new(config.endpoint_config.clone());

        Ok(Self {
            config,
            vad_manager,
            asr_recognizer,
            punctuation_engine,
            endpoint_detector,
            asr_stream: None,
            pipeline_state: PipelineState::Idle,
            speech_start_time: None,
            asr_endpoint_grace_remaining: 0,
            total_frames: 0,
            asr_frames: 0,
        })
    }

    /// å¤„ç†éŸ³é¢‘å¸§
    ///
    /// # å‚æ•°
    /// - `samples`: éŸ³é¢‘æ ·æœ¬ (f32, [-1.0, 1.0])
    ///   - å¯¹äº 16kHz: 512 samples (32ms)
    ///
    /// # è¿”å›
    /// - `StreamingResult`: æµå¼è¯†åˆ«ç»“æœ
    pub fn process(&mut self, samples: &[f32]) -> VInputResult<StreamingResult> {
        self.total_frames += 1;

        // 1. VAD å¤„ç†
        let vad_result = self.vad_manager.process(samples)?;
        let now = Instant::now();

        // 1.5 å°†éŸ³é¢‘é€å…¥ç«¯ç‚¹æ£€æµ‹å™¨ï¼ˆç”¨äºèƒ½é‡åˆ†æï¼‰
        if self.pipeline_state == PipelineState::Recognizing {
            self.endpoint_detector.feed_audio(samples);
        }

        // 2. ç«¯ç‚¹æ£€æµ‹å¤„ç†ï¼ˆä½¿ç”¨ EndpointDetectorï¼‰
        let is_speech = matches!(vad_result.state, VadState::Speech | VadState::SpeechCandidate);
        let endpoint_result = self.endpoint_detector.process_vad(is_speech);

        // 3. æ ¹æ®ç«¯ç‚¹æ£€æµ‹ç»“æœå¤„ç†çŠ¶æ€
        match endpoint_result {
            EndpointResult::TooShort => {
                // è¯­éŸ³è¿‡çŸ­ï¼Œå¿½ç•¥å¹¶é‡ç½®
                tracing::info!("Pipeline: è¯­éŸ³è¿‡çŸ­ï¼Œå¿½ç•¥");
                self.reset()?;
                self.pipeline_state = PipelineState::Idle;
            }
            EndpointResult::ForcedSegmentation => {
                // è¯­éŸ³è¿‡é•¿ï¼Œå¼ºåˆ¶åˆ†æ®µ
                tracing::info!("Pipeline: è¯­éŸ³è¿‡é•¿ï¼Œå¼ºåˆ¶åˆ†æ®µ");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Timeout => {
                // å¼ºåˆ¶è¶…æ—¶
                tracing::warn!("Pipeline: å¼ºåˆ¶è¶…æ—¶");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Detected => {
                // æ£€æµ‹åˆ°ç«¯ç‚¹
                tracing::info!("Pipeline: VAD ç«¯ç‚¹æ£€æµ‹å®Œæˆ");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Continue => {
                // ç»§ç»­å¤„ç†ï¼Œæ ¹æ® VAD çŠ¶æ€ç®¡ç† ASR æµ
                match (self.pipeline_state, vad_result.state) {
                    // ä»ç©ºé—²çŠ¶æ€æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                    (PipelineState::Idle, VadState::Speech) if vad_result.state_changed => {
                        tracing::info!("Pipeline: Speech detected, starting ASR");

                        // åˆ›å»ºæ–°çš„ ASR æµ
                        let mut stream = self.asr_recognizer.create_stream()?;
                        tracing::info!("âœ… ASR æµåˆ›å»ºæˆåŠŸ");

                        // æ³¨å…¥ Pre-roll éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
                        if let Some(pre_roll_audio) = &vad_result.pre_roll_audio {
                            if !pre_roll_audio.is_empty() {
                                stream.accept_waveform(
                                    pre_roll_audio,
                                    self.config.vad_config.silero.sample_rate as i32,
                                );
                                self.asr_frames += 1;
                                tracing::info!(
                                    "âœ… æ³¨å…¥ Pre-roll éŸ³é¢‘: {} æ ·æœ¬",
                                    pre_roll_audio.len()
                                );
                            }
                        }

                        let stream_static: OnlineStream<'static> = unsafe {
                            std::mem::transmute(stream)
                        };
                        self.asr_stream = Some(stream_static);

                        self.pipeline_state = PipelineState::Recognizing;
                        self.speech_start_time = Some(now);
                    }

                    // è¯†åˆ«ä¸­ï¼Œç»§ç»­é€å…¥éŸ³é¢‘
                    (PipelineState::Recognizing, VadState::Speech | VadState::SpeechCandidate | VadState::SilenceCandidate) => {
                        if self.asr_stream.is_some() {
                            let samples_vec = samples.to_vec();
                            self.feed_audio_to_asr_internal(&samples_vec)?;
                        }
                    }

                    _ => {
                        // å…¶ä»–çŠ¶æ€ç»„åˆï¼Œä¸åšå¤„ç†
                    }
                }
            }
        }

        // 4. æ‰§è¡Œ ASR è§£ç ï¼ˆå¦‚æœæµå‡†å¤‡å¥½ï¼‰å¹¶æ£€æŸ¥ ASR ç«¯ç‚¹
        if self.pipeline_state == PipelineState::Recognizing {
            if let Some(stream) = &mut self.asr_stream {
                if stream.is_ready(&self.asr_recognizer) {
                    stream.decode(&self.asr_recognizer);
                }

                if self.asr_endpoint_grace_remaining > 0 {
                    // å¤„äº ASR endpoint ç¼“å†²æœŸï¼šç»§ç»­å–‚éŸ³é¢‘ï¼Œå€’è®¡æ—¶
                    self.asr_endpoint_grace_remaining -= 1;
                    if self.asr_endpoint_grace_remaining == 0 {
                        // ç¼“å†²æœŸç»“æŸï¼šåˆ·æ–°å¹¶æäº¤
                        stream.input_finished();
                        self.pipeline_state = PipelineState::Completed;
                        tracing::info!("Pipeline: ASR ç«¯ç‚¹ç¼“å†²æœŸç»“æŸï¼Œå‡†å¤‡ä¸Šå±");
                    } else {
                        // ç¼“å†²æœŸå†…ç»§ç»­å–‚éŸ³é¢‘ï¼ˆå·²åœ¨ä¸Šæ–¹çš„ Recognizing åˆ†æ”¯å¤„ç†ï¼‰
                        tracing::debug!("Pipeline: ASR ç«¯ç‚¹ç¼“å†²æœŸå‰©ä½™ {} å¸§", self.asr_endpoint_grace_remaining);
                    }
                } else {
                    // æ­£å¸¸æ£€æŸ¥ ASR ç«¯ç‚¹ï¼ˆåªåœ¨ç¼“å†²æœŸå¤–æ£€æŸ¥ï¼Œé¿å…é‡å¤è§¦å‘ï¼‰
                    let asr_endpoint = stream.is_endpoint(&self.asr_recognizer);
                    let asr_result = self.endpoint_detector.process_asr_endpoint(asr_endpoint);

                    if asr_result == EndpointResult::Detected {
                        // å¯åŠ¨ 5 å¸§ï¼ˆçº¦ 160msï¼‰ç¼“å†²æœŸï¼Œè®© Paraformer å®Œæˆæœ«å­—è§£ç 
                        const GRACE_FRAMES: u32 = 5;
                        tracing::info!("Pipeline: ASR ç«¯ç‚¹æ£€æµ‹å®Œæˆï¼Œç­‰å¾… {}ms ç¼“å†²æœŸä»¥ç¡®ä¿æœ«å­—å®Œæ•´",
                            GRACE_FRAMES * 32);
                        self.asr_endpoint_grace_remaining = GRACE_FRAMES;
                    }
                }
            }
        }

        // 5. è·å–è¯†åˆ«ç»“æœ
        let partial_result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        let is_final = self.pipeline_state == PipelineState::Completed;

        let duration_ms = self.speech_start_time
            .map(|start| now.duration_since(start).as_millis() as u64)
            .unwrap_or(0);

        // 6. åˆ†ç¦»ç¨³å®šå’Œä¸ç¨³å®šæ–‡æœ¬
        let (stable_text, unstable_text) = self.split_stable_unstable(&partial_result);

        // 7. æ£€æµ‹æ˜¯å¦åº”è¯¥æ·»åŠ é€—å·ï¼ˆåœé¡¿æ£€æµ‹ï¼‰
        let should_add_comma = false; // TODO: å®ç°åœé¡¿æ£€æµ‹é€»è¾‘

        Ok(StreamingResult {
            partial_result,
            stable_text,
            unstable_text,
            should_add_comma,
            is_final,
            vad_state: vad_result.state,
            pipeline_state: self.pipeline_state,
            speech_prob: vad_result.speech_prob,
            duration_ms,
        })
    }

    /// å°†éŸ³é¢‘æ•°æ®é€å…¥ ASRï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œé¿å…å€Ÿç”¨å†²çªï¼‰
    fn feed_audio_to_asr_internal(&mut self, samples: &[f32]) -> VInputResult<()> {
        if let Some(stream) = &mut self.asr_stream {
            stream.accept_waveform(
                samples,
                self.config.vad_config.silero.sample_rate as i32,
            );
            self.asr_frames += 1;

            // æ¯ 50 å¸§ï¼ˆçº¦ 1.6 ç§’ï¼‰æ‰“å°ä¸€æ¬¡æ—¥å¿—
            if self.asr_frames % 50 == 0 {
                tracing::debug!("ğŸ¤ å·²é€å…¥ {} å¸§éŸ³é¢‘åˆ° ASR (æ¯å¸§ {} æ ·æœ¬)",
                    self.asr_frames, samples.len());
            }
        }
        Ok(())
    }

    /// é‡ç½®ç®¡é“çŠ¶æ€
    pub fn reset(&mut self) -> VInputResult<()> {
        tracing::debug!("Pipeline: Resetting");

        // é”€æ¯ ASR æµ
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }

        // é‡ç½® VAD
        self.vad_manager.reset();

        // é‡ç½®æ ‡ç‚¹å¼•æ“
        self.punctuation_engine.reset_sentence();

        // é‡ç½®ç«¯ç‚¹æ£€æµ‹å™¨
        self.endpoint_detector.reset();

        // é‡ç½®çŠ¶æ€
        self.pipeline_state = PipelineState::Idle;
        self.speech_start_time = None;
        self.asr_endpoint_grace_remaining = 0;

        Ok(())
    }

    /// å¼ºåˆ¶è®¾ç½® VAD çŠ¶æ€ï¼ˆç”¨äº PushToTalk æ¨¡å¼ï¼‰
    pub fn force_vad_state(&mut self, state: VadState) {
        self.vad_manager.force_state(state);
    }

    /// è·å–å½“å‰ç®¡é“çŠ¶æ€
    pub fn pipeline_state(&self) -> PipelineState {
        self.pipeline_state
    }

    /// è·å– VAD çŠ¶æ€
    pub fn vad_state(&self) -> VadState {
        self.vad_manager.state()
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    pub fn stats(&self) -> PipelineStats {
        PipelineStats {
            total_frames: self.total_frames,
            asr_frames: self.asr_frames,
            speech_duration_ms: self.speech_start_time
                .map(|start| Instant::now().duration_since(start).as_millis() as u64)
                .unwrap_or(0),
        }
    }

    /// åˆ†ç¦»ç¨³å®šå’Œä¸ç¨³å®šæ–‡æœ¬
    ///
    /// ä¿ç•™æœ€å N ä¸ªå­—ç¬¦åœ¨ Preeditï¼ˆä¸ç¨³å®šï¼‰ï¼Œå…¶ä½™éƒ¨åˆ†å¯ä»¥ç«‹å³ä¸Šå±ï¼ˆç¨³å®šï¼‰
    ///
    /// æ™ºèƒ½è¿‡æ»¤ï¼šå¦‚æœæ•´ä¸ªè¯†åˆ«ç»“æœåŒ…å«ä¸­æ–‡æ•°å­—ï¼Œåˆ™å…¨éƒ¨ä¿ç•™åœ¨ Preeditï¼Œ
    /// é¿å… ITN è½¬æ¢æ—¶æ— æ³•ä¿®æ”¹å·²ä¸Šå±çš„æ•°å­—
    fn split_stable_unstable(&self, text: &str) -> (String, String) {
        // ğŸ¯ ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœæ•´ä¸ªæ–‡æœ¬åŒ…å«ä¸­æ–‡æ•°å­—ï¼Œå…¨éƒ¨ä¿ç•™åœ¨ Preedit
        if Self::contains_chinese_number(text) {
            return (String::new(), text.to_string());
        }

        // å¦‚æœä¸åŒ…å«æ•°å­—ï¼ŒæŒ‰æ­£å¸¸é€»è¾‘åˆ†ç¦»
        const KEEP_LAST_CHARS: usize = 2; // ä¿ç•™æœ€å2ä¸ªå­—ç¬¦åœ¨ Preedit

        let chars: Vec<char> = text.chars().collect();

        if chars.len() <= KEEP_LAST_CHARS {
            // å…¨éƒ¨ä¸ç¨³å®š
            return (String::new(), text.to_string());
        }

        let stable_count = chars.len() - KEEP_LAST_CHARS;
        let stable: String = chars[..stable_count].iter().collect();
        let unstable: String = chars[stable_count..].iter().collect();

        (stable, unstable)
    }

    /// æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡æ•°å­—å­—ç¬¦
    ///
    /// ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å»¶è¿Ÿä¸Šå±ï¼Œç­‰å¾… ITN å¤„ç†
    fn contains_chinese_number(text: &str) -> bool {
        text.chars().any(|c| matches!(c,
            'é›¶' | 'ä¸€' | 'äºŒ' | 'ä¸‰' | 'å››' | 'äº”' | 'å…­' | 'ä¸ƒ' | 'å…«' | 'ä¹' |
            'å' | 'ç™¾' | 'åƒ' | 'ä¸‡' | 'äº¿' | 'ç‚¹'
        ))
    }

    /// è·å–å®æ—¶è¯†åˆ«ç»“æœï¼ˆå¸¦å®æ—¶æ ‡ç‚¹å¤„ç†ï¼‰
    ///
    /// ç”¨äºåœ¨è¯†åˆ«è¿‡ç¨‹ä¸­æ˜¾ç¤ºå¸¦æ ‡ç‚¹çš„ Preedit
    /// ä¸ä¼šé‡ç½®ç®¡é“çŠ¶æ€ï¼Œä¸ä¼šæ·»åŠ å¥å°¾æ ‡ç‚¹
    pub fn get_partial_result_with_punctuation(&mut self) -> String {
        if let Some(stream) = &self.asr_stream {
            // è·å–è¯¦ç»†ç»“æœï¼ˆåŒ…å« Token å’Œæ—¶é—´æˆ³ï¼‰
            let detailed_result = stream.get_detailed_result(&self.asr_recognizer);

            if detailed_result.is_empty() {
                return String::new();
            }

            // å¤„ç†æ¯ä¸ª Tokenï¼Œæ·»åŠ é€—å·ï¼ˆä½†ä¸æ·»åŠ å¥å°¾æ ‡ç‚¹ï¼‰
            let mut text_with_commas = String::new();

            for token in &detailed_result.tokens {
                // è½¬æ¢ä¸º TokenInfo
                let token_info = token.to_token_info();

                // å¤„ç† Tokenï¼ˆå¯èƒ½åœ¨å‰é¢æ·»åŠ é€—å·ï¼‰
                if let Some(processed_token) = self.punctuation_engine.process_token(token_info) {
                    text_with_commas.push_str(&processed_token);
                }
            }

            text_with_commas
        } else {
            String::new()
        }
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆå¸¦æ ‡ç‚¹ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result_with_punctuation(&mut self) -> String {
        // é€šçŸ¥è§£ç å™¨è¾“å…¥å·²ç»“æŸï¼Œè§¦å‘æœ€ç»ˆ beam search å®Œæˆ
        // å¯¹äºè½»å£°æœ«å­—ï¼šASR ç¼“å†²åŒºé‡Œæœ‰è¿™äº›å¸§ï¼Œä½†æœªç» input_finished() å°±æ— æ³•æäº¤
        if let Some(stream) = &mut self.asr_stream {
            tracing::info!("ğŸ”š è°ƒç”¨ input_finished()ï¼Œåˆ·æ–° ASR è§£ç å™¨ç¼“å†²åŒº");
            stream.input_finished();
        }

        // æœ€ç»ˆä¸€æ¬¡è§£ç ï¼Œå¤„ç† input_finished() åçš„å‰©ä½™å¸§
        if let Some(stream) = &mut self.asr_stream {
            if stream.is_ready(&self.asr_recognizer) {
                stream.decode(&self.asr_recognizer);
                tracing::info!("ğŸ”š æœ€ç»ˆè§£ç å®Œæˆ");
            }
        }

        let result = if let Some(stream) = &self.asr_stream {
            // è·å–è¯¦ç»†ç»“æœï¼ˆåŒ…å« Token å’Œæ—¶é—´æˆ³ï¼‰
            let detailed_result = stream.get_detailed_result(&self.asr_recognizer);

            tracing::info!("ğŸ“Š ASR è¯†åˆ«ç»“æœè¯¦æƒ…:");
            tracing::info!("  - text: '{}'", detailed_result.text);
            tracing::info!("  - text.len(): {}", detailed_result.text.len());
            tracing::info!("  - token_count: {}", detailed_result.tokens.len());
            tracing::info!("  - is_empty(): {}", detailed_result.is_empty());

            if detailed_result.is_empty() {
                tracing::warn!("âš ï¸  è¯†åˆ«ç»“æœä¸ºç©ºï¼ˆtext ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰");
                String::new()
            } else {
                // æ‰“å°æ‰€æœ‰ Token ä¿¡æ¯ï¼ˆINFO çº§åˆ«ï¼Œå¸®åŠ©åˆ†ææ–­å¥ï¼‰
                for (i, token) in detailed_result.tokens.iter().enumerate() {
                    tracing::info!("  Token[{}]: '{}' ({}ms - {}ms, duration={}ms)",
                        i, token.text, token.start_time_ms, token.end_time_ms, token.duration_ms());
                }

                // ç¬¬ä¸€æ­¥ï¼šæ„å»ºçº¯æ–‡æœ¬ï¼ˆæ— é€—å·ï¼‰ï¼ŒåŒæ—¶æ”¶é›†é€»è¾‘è¿æ¥è¯çš„é€—å·ä½ç½®
                // PauseEngine çš„æ—¶é—´æˆ³æ–¹æ³•å¯¹ Paraformer æ¨¡å‹æ— æ•ˆï¼Œè·³è¿‡åœé¡¿æ£€æµ‹
                // åªä¿ç•™ RuleLayer çš„é€»è¾‘è¿æ¥è¯é€—å·ï¼ˆå¦‚"å› ä¸º"ã€"æ‰€ä»¥"ï¼‰
                let mut plain_text = String::new();
                let mut logic_comma_positions: Vec<usize> = Vec::new(); // é€»è¾‘è¯å‰çš„å­—ç¬¦ä½ç½®
                let mut token_char_count = 0usize;

                for token in &detailed_result.tokens {
                    let token_info = token.to_token_info();
                    let word = token_info.text.trim().to_string();
                    if word.is_empty() || word == "NE" {
                        continue;
                    }
                    // æ£€æŸ¥é€»è¾‘è¿æ¥è¯è§„åˆ™ï¼ˆåœ¨è¯ã€å‰ã€‘æ’å…¥é€—å·ï¼Œä¸ä¾èµ–æ—¶é—´æˆ³ï¼Œå§‹ç»ˆæœ‰æ•ˆï¼‰
                    let is_logic_word = crate::punctuation::rules::RuleLayer::is_logic_word(&word);
                    if is_logic_word && token_char_count >= 8 {
                        logic_comma_positions.push(token_char_count);
                    }
                    plain_text.push_str(&word);
                    token_char_count += word.chars().count();
                }

                tracing::info!("ğŸ“ çº¯æ–‡æœ¬: '{}', é€»è¾‘è¯é€—å·ä½ç½®: {:?}",
                    plain_text, logic_comma_positions);

                // ç¬¬äºŒæ­¥ï¼šå°†é€»è¾‘è¿æ¥è¯é€—å·ä½ç½®æ’å…¥çº¯æ–‡æœ¬
                let mut comma_positions = logic_comma_positions;
                comma_positions.sort_unstable();
                comma_positions.dedup();

                // ç¬¬å››æ­¥ï¼šå°†é€—å·æ’å…¥åˆ°çº¯æ–‡æœ¬çš„å¯¹åº”å­—ç¬¦ä½ç½®
                const MIN_CHARS_BETWEEN_COMMAS: usize = 3;
                let mut final_text = String::with_capacity(plain_text.len() + comma_positions.len() * 3);
                let mut last_comma_at: Option<usize> = None;

                for (i, ch) in plain_text.char_indices().map(|(_, c)| c).enumerate() {
                    // æ£€æŸ¥æ­¤ä½ç½®æ˜¯å¦åº”æ’å…¥é€—å·
                    if i > 0 && comma_positions.contains(&i) {
                        let ok = match last_comma_at {
                            None => i >= MIN_CHARS_BETWEEN_COMMAS,
                            Some(last) => i >= last + MIN_CHARS_BETWEEN_COMMAS,
                        };
                        if ok {
                            tracing::info!("  âœ… åœ¨ç¬¬ {} ä¸ªå­—ç¬¦å‰æ’å…¥é€—å·", i);
                            final_text.push('ï¼Œ');
                            last_comma_at = Some(i);
                        }
                    }
                    final_text.push(ch);
                }

                tracing::info!("ğŸ“ æ’å…¥é€—å·å: '{}'", final_text);

                // æ£€æµ‹ VAD èƒ½é‡å˜åŒ–ï¼ˆç”¨äºé—®å·æ£€æµ‹ï¼‰
                let energy_rising = self.endpoint_detector.analyze_energy_trend();

                // è·å–è¯­éŸ³æŒç»­æ—¶é—´ç”¨äºæ ‡ç‚¹å†³ç­–
                // âš ï¸  ç”¨ asr_frames Ã— 32ms è€Œéå¢™ä¸Šæ—¶é’Ÿ
                //     ç†ç”±ï¼šå¿«é€Ÿå¤„ç†ï¼ˆæµ‹è¯•å›æ”¾ï¼‰æ—¶å¢™ä¸Šæ—¶é’Ÿè¿œçŸ­äºå®é™…éŸ³é¢‘æ—¶é•¿
                let speech_duration_ms = self.asr_frames * 32;

                tracing::debug!("ğŸ”š å‡†å¤‡æ·»åŠ å¥å°¾æ ‡ç‚¹: speech_duration_ms={}, energy_rising={}",
                    speech_duration_ms, energy_rising);

                // ğŸ¯ å¦‚æœæœ€åä¸€ä¸ªå­—ç¬¦æ˜¯é€—å·ï¼Œæ›¿æ¢ä¸ºå¥å°¾æ ‡ç‚¹
                if final_text.ends_with('ï¼Œ') {
                    final_text.pop(); // ç§»é™¤æœ€åçš„é€—å·
                    tracing::debug!("  æ£€æµ‹åˆ°æœ«å°¾é€—å·ï¼Œå°†æ›¿æ¢ä¸ºå¥å°¾æ ‡ç‚¹");
                }

                // æ·»åŠ å¥å°¾æ ‡ç‚¹
                // ç”¨ determine_ending(final_text) è€Œé finalize_sentence()
                // åŸå› ï¼šfinalize_sentence ä¾èµ– current_sentenceï¼ˆç”± process_token å¡«å……ï¼‰ï¼Œ
                //       ä½†å½“å‰æµç¨‹ç›´æ¥æ„å»º final_textï¼Œcurrent_sentence å§‹ç»ˆä¸ºç©º
                let ending = self.punctuation_engine.determine_ending(
                    &final_text,
                    speech_duration_ms,
                    energy_rising,
                );

                tracing::info!("  å¥å°¾æ ‡ç‚¹: '{}'ï¼ˆåŸºäºæ–‡æœ¬: '{}'ï¼‰", ending, final_text);
                final_text.push_str(&ending);

                tracing::info!("âœ… æ ‡ç‚¹å¤„ç†å®Œæˆ: '{}'", final_text);
                final_text
            }
        } else {
            tracing::warn!("âš ï¸  ASR æµä¸ºç©º");
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆä¸å¸¦æ ‡ç‚¹ï¼ŒåŸå§‹æ–‡æœ¬ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result(&mut self) -> String {
        let result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }
}

impl Drop for StreamingPipeline {
    fn drop(&mut self) {
        // ç¡®ä¿ ASR æµåœ¨ç®¡é“é”€æ¯å‰è¢«æ¸…ç†
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }
    }
}

/// ç®¡é“ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct PipelineStats {
    /// å¤„ç†çš„æ€»å¸§æ•°
    pub total_frames: u64,
    /// é€å…¥ ASR çš„å¸§æ•°
    pub asr_frames: u64,
    /// è¯­éŸ³æŒç»­æ—¶é—´ (ms)
    pub speech_duration_ms: u64,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_pipeline_state_transitions() {
        assert_eq!(PipelineState::Idle, PipelineState::Idle);
        assert_ne!(PipelineState::Idle, PipelineState::Recognizing);
    }
}
