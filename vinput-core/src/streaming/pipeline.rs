//! Streaming Pipeline - VAD-ASR æµå¼è¯†åˆ«ç®¡é“
//!
//! å°† VAD æ£€æµ‹ç»“æœä¸ ASR è¯†åˆ«å™¨è¿æ¥ï¼Œå®ç°ç«¯åˆ°ç«¯çš„æµå¼è¯­éŸ³è¯†åˆ«

use crate::asr::{OnlineRecognizer, OnlineRecognizerConfig, OnlineStream};
use crate::endpointing::{EndpointDetector, EndpointDetectorConfig, EndpointResult};
use crate::error::VInputResult;
use crate::punctuation::{PunctuationEngine, StyleProfile};
use crate::vad::{VadConfig, VadManager, VadState};
use std::time::Instant;

/// æµå¼ç®¡é“é…ç½®
#[derive(Debug, Clone)]
pub struct StreamingConfig {
    /// VAD é…ç½®
    pub vad_config: VadConfig,
    /// ASR é…ç½®
    pub asr_config: OnlineRecognizerConfig,
    /// æ ‡ç‚¹é£æ ¼é…ç½®
    pub punctuation_profile: StyleProfile,
    /// ç«¯ç‚¹æ£€æµ‹é…ç½®
    pub endpoint_config: EndpointDetectorConfig,
}

impl Default for StreamingConfig {
    fn default() -> Self {
        Self {
            vad_config: VadConfig::push_to_talk_default(),
            asr_config: OnlineRecognizerConfig::default(),
            punctuation_profile: StyleProfile::default(),
            endpoint_config: EndpointDetectorConfig::default(),
        }
    }
}

/// ç®¡é“çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PipelineState {
    /// ç©ºé—²çŠ¶æ€ï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥
    Idle,
    /// æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ­£åœ¨è¯†åˆ«
    Recognizing,
    /// è¯†åˆ«å®Œæˆï¼Œç­‰å¾…é‡ç½®
    Completed,
}

/// æµå¼è¯†åˆ«ç»“æœ
#[derive(Debug, Clone)]
pub struct StreamingResult {
    /// å½“å‰è¯†åˆ«çš„éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ›´æ–°ï¼‰
    pub partial_result: String,
    /// ç¨³å®šçš„æ–‡æœ¬ï¼ˆå¯ä»¥ç«‹å³ä¸Šå±ï¼‰
    pub stable_text: String,
    /// ä¸ç¨³å®šçš„æ–‡æœ¬ï¼ˆä¿ç•™åœ¨ Preeditï¼‰
    pub unstable_text: String,
    /// æ˜¯å¦åº”è¯¥æ·»åŠ é€—å·ï¼ˆæ£€æµ‹åˆ°åœé¡¿ï¼‰
    pub should_add_comma: bool,
    /// æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
    pub is_final: bool,
    /// VAD çŠ¶æ€
    pub vad_state: VadState,
    /// ç®¡é“çŠ¶æ€
    pub pipeline_state: PipelineState,
    /// è¯­éŸ³æ¦‚ç‡
    pub speech_prob: f32,
    /// è‡ªä¸Šæ¬¡è¯­éŸ³å¼€å§‹ä»¥æ¥çš„æŒç»­æ—¶é—´ (ms)
    pub duration_ms: u64,
}

/// VAD-ASR æµå¼è¯†åˆ«ç®¡é“
pub struct StreamingPipeline {
    config: StreamingConfig,
    vad_manager: VadManager,
    asr_recognizer: OnlineRecognizer,
    asr_stream: Option<OnlineStream<'static>>,
    punctuation_engine: PunctuationEngine,
    endpoint_detector: EndpointDetector,
    pipeline_state: PipelineState,

    /// è¯­éŸ³å¼€å§‹æ—¶é—´
    speech_start_time: Option<Instant>,

    /// ç´¯ç§¯çš„éŸ³é¢‘å¸§æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    total_frames: u64,
    /// é€å…¥ ASR çš„éŸ³é¢‘å¸§æ•°
    asr_frames: u64,
}

impl StreamingPipeline {
    /// åˆ›å»ºæ–°çš„æµå¼ç®¡é“
    pub fn new(config: StreamingConfig) -> VInputResult<Self> {
        tracing::info!("ğŸ“ StreamingPipeline::new - æ¥æ”¶åˆ°çš„æ ‡ç‚¹é…ç½®: pause_ratio={}, min_tokens={}",
            config.punctuation_profile.streaming_pause_ratio,
            config.punctuation_profile.streaming_min_tokens
        );
        tracing::info!("ğŸ¯ ç«¯ç‚¹æ£€æµ‹é…ç½®: trailing_silence={}ms, min_speech={}ms",
            config.endpoint_config.trailing_silence_ms,
            config.endpoint_config.min_speech_duration_ms
        );

        let vad_manager = VadManager::new(config.vad_config.clone())?;
        let asr_recognizer = OnlineRecognizer::new(&config.asr_config)?;
        let punctuation_engine = PunctuationEngine::new(config.punctuation_profile.clone());
        let endpoint_detector = EndpointDetector::new(config.endpoint_config.clone());

        Ok(Self {
            config,
            vad_manager,
            asr_recognizer,
            punctuation_engine,
            endpoint_detector,
            asr_stream: None,
            pipeline_state: PipelineState::Idle,
            speech_start_time: None,
            total_frames: 0,
            asr_frames: 0,
        })
    }

    /// å¤„ç†éŸ³é¢‘å¸§
    ///
    /// # å‚æ•°
    /// - `samples`: éŸ³é¢‘æ ·æœ¬ (f32, [-1.0, 1.0])
    ///   - å¯¹äº 16kHz: 512 samples (32ms)
    ///
    /// # è¿”å›
    /// - `StreamingResult`: æµå¼è¯†åˆ«ç»“æœ
    pub fn process(&mut self, samples: &[f32]) -> VInputResult<StreamingResult> {
        self.total_frames += 1;

        // 1. VAD å¤„ç†
        let vad_result = self.vad_manager.process(samples)?;
        let now = Instant::now();

        // 1.5 å°†éŸ³é¢‘é€å…¥ç«¯ç‚¹æ£€æµ‹å™¨ï¼ˆç”¨äºèƒ½é‡åˆ†æï¼‰
        if self.pipeline_state == PipelineState::Recognizing {
            self.endpoint_detector.feed_audio(samples);
        }

        // 2. ç«¯ç‚¹æ£€æµ‹å¤„ç†ï¼ˆä½¿ç”¨ EndpointDetectorï¼‰
        let is_speech = matches!(vad_result.state, VadState::Speech | VadState::SpeechCandidate);
        let endpoint_result = self.endpoint_detector.process_vad(is_speech);

        // 3. æ ¹æ®ç«¯ç‚¹æ£€æµ‹ç»“æœå¤„ç†çŠ¶æ€
        match endpoint_result {
            EndpointResult::TooShort => {
                // è¯­éŸ³è¿‡çŸ­ï¼Œå¿½ç•¥å¹¶é‡ç½®
                tracing::info!("Pipeline: è¯­éŸ³è¿‡çŸ­ï¼Œå¿½ç•¥");
                self.reset()?;
                self.pipeline_state = PipelineState::Idle;
            }
            EndpointResult::ForcedSegmentation => {
                // è¯­éŸ³è¿‡é•¿ï¼Œå¼ºåˆ¶åˆ†æ®µ
                tracing::info!("Pipeline: è¯­éŸ³è¿‡é•¿ï¼Œå¼ºåˆ¶åˆ†æ®µ");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Timeout => {
                // å¼ºåˆ¶è¶…æ—¶
                tracing::warn!("Pipeline: å¼ºåˆ¶è¶…æ—¶");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Detected => {
                // æ£€æµ‹åˆ°ç«¯ç‚¹
                tracing::info!("Pipeline: VAD ç«¯ç‚¹æ£€æµ‹å®Œæˆ");
                if let Some(stream) = &mut self.asr_stream {
                    stream.input_finished();
                }
                self.pipeline_state = PipelineState::Completed;
            }
            EndpointResult::Continue => {
                // ç»§ç»­å¤„ç†ï¼Œæ ¹æ® VAD çŠ¶æ€ç®¡ç† ASR æµ
                match (self.pipeline_state, vad_result.state) {
                    // ä»ç©ºé—²çŠ¶æ€æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                    (PipelineState::Idle, VadState::Speech) if vad_result.state_changed => {
                        tracing::info!("Pipeline: Speech detected, starting ASR");

                        // åˆ›å»ºæ–°çš„ ASR æµ
                        let mut stream = self.asr_recognizer.create_stream()?;

                        // æ³¨å…¥ Pre-roll éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
                        if let Some(pre_roll_audio) = &vad_result.pre_roll_audio {
                            if !pre_roll_audio.is_empty() {
                                stream.accept_waveform(
                                    pre_roll_audio,
                                    self.config.vad_config.silero.sample_rate as i32,
                                );
                                self.asr_frames += 1;
                                tracing::debug!(
                                    "Pipeline: Injected {} pre-roll samples",
                                    pre_roll_audio.len()
                                );
                            }
                        }

                        let stream_static: OnlineStream<'static> = unsafe {
                            std::mem::transmute(stream)
                        };
                        self.asr_stream = Some(stream_static);

                        self.pipeline_state = PipelineState::Recognizing;
                        self.speech_start_time = Some(now);
                    }

                    // è¯†åˆ«ä¸­ï¼Œç»§ç»­é€å…¥éŸ³é¢‘
                    (PipelineState::Recognizing, VadState::Speech | VadState::SpeechCandidate | VadState::SilenceCandidate) => {
                        if self.asr_stream.is_some() {
                            let samples_vec = samples.to_vec();
                            self.feed_audio_to_asr_internal(&samples_vec)?;
                        }
                    }

                    _ => {
                        // å…¶ä»–çŠ¶æ€ç»„åˆï¼Œä¸åšå¤„ç†
                    }
                }
            }
        }

        // 4. æ‰§è¡Œ ASR è§£ç ï¼ˆå¦‚æœæµå‡†å¤‡å¥½ï¼‰å¹¶æ£€æŸ¥ ASR ç«¯ç‚¹
        if self.pipeline_state == PipelineState::Recognizing {
            if let Some(stream) = &mut self.asr_stream {
                if stream.is_ready(&self.asr_recognizer) {
                    stream.decode(&self.asr_recognizer);
                }

                // ä½¿ç”¨ EndpointDetector æ£€æŸ¥ ASR ç«¯ç‚¹
                let asr_endpoint = stream.is_endpoint(&self.asr_recognizer);
                let asr_result = self.endpoint_detector.process_asr_endpoint(asr_endpoint);

                if asr_result == EndpointResult::Detected {
                    tracing::info!("Pipeline: ASR ç«¯ç‚¹æ£€æµ‹å®Œæˆ");
                    stream.input_finished();
                    self.pipeline_state = PipelineState::Completed;
                }
            }
        }

        // 5. è·å–è¯†åˆ«ç»“æœ
        let partial_result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        let is_final = self.pipeline_state == PipelineState::Completed;

        let duration_ms = self.speech_start_time
            .map(|start| now.duration_since(start).as_millis() as u64)
            .unwrap_or(0);

        // 6. åˆ†ç¦»ç¨³å®šå’Œä¸ç¨³å®šæ–‡æœ¬
        let (stable_text, unstable_text) = self.split_stable_unstable(&partial_result);

        // 7. æ£€æµ‹æ˜¯å¦åº”è¯¥æ·»åŠ é€—å·ï¼ˆåœé¡¿æ£€æµ‹ï¼‰
        let should_add_comma = false; // TODO: å®ç°åœé¡¿æ£€æµ‹é€»è¾‘

        Ok(StreamingResult {
            partial_result,
            stable_text,
            unstable_text,
            should_add_comma,
            is_final,
            vad_state: vad_result.state,
            pipeline_state: self.pipeline_state,
            speech_prob: vad_result.speech_prob,
            duration_ms,
        })
    }

    /// å°†éŸ³é¢‘æ•°æ®é€å…¥ ASRï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œé¿å…å€Ÿç”¨å†²çªï¼‰
    fn feed_audio_to_asr_internal(&mut self, samples: &[f32]) -> VInputResult<()> {
        if let Some(stream) = &mut self.asr_stream {
            stream.accept_waveform(
                samples,
                self.config.vad_config.silero.sample_rate as i32,
            );
            self.asr_frames += 1;
        }
        Ok(())
    }

    /// é‡ç½®ç®¡é“çŠ¶æ€
    pub fn reset(&mut self) -> VInputResult<()> {
        tracing::debug!("Pipeline: Resetting");

        // é”€æ¯ ASR æµ
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }

        // é‡ç½® VAD
        self.vad_manager.reset();

        // é‡ç½®æ ‡ç‚¹å¼•æ“
        self.punctuation_engine.reset_sentence();

        // é‡ç½®ç«¯ç‚¹æ£€æµ‹å™¨
        self.endpoint_detector.reset();

        // é‡ç½®çŠ¶æ€
        self.pipeline_state = PipelineState::Idle;
        self.speech_start_time = None;

        Ok(())
    }

    /// å¼ºåˆ¶è®¾ç½® VAD çŠ¶æ€ï¼ˆç”¨äº PushToTalk æ¨¡å¼ï¼‰
    pub fn force_vad_state(&mut self, state: VadState) {
        self.vad_manager.force_state(state);
    }

    /// è·å–å½“å‰ç®¡é“çŠ¶æ€
    pub fn pipeline_state(&self) -> PipelineState {
        self.pipeline_state
    }

    /// è·å– VAD çŠ¶æ€
    pub fn vad_state(&self) -> VadState {
        self.vad_manager.state()
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    pub fn stats(&self) -> PipelineStats {
        PipelineStats {
            total_frames: self.total_frames,
            asr_frames: self.asr_frames,
            speech_duration_ms: self.speech_start_time
                .map(|start| Instant::now().duration_since(start).as_millis() as u64)
                .unwrap_or(0),
        }
    }

    /// åˆ†ç¦»ç¨³å®šå’Œä¸ç¨³å®šæ–‡æœ¬
    ///
    /// ä¿ç•™æœ€å N ä¸ªå­—ç¬¦åœ¨ Preeditï¼ˆä¸ç¨³å®šï¼‰ï¼Œå…¶ä½™éƒ¨åˆ†å¯ä»¥ç«‹å³ä¸Šå±ï¼ˆç¨³å®šï¼‰
    ///
    /// æ™ºèƒ½è¿‡æ»¤ï¼šå¦‚æœæ•´ä¸ªè¯†åˆ«ç»“æœåŒ…å«ä¸­æ–‡æ•°å­—ï¼Œåˆ™å…¨éƒ¨ä¿ç•™åœ¨ Preeditï¼Œ
    /// é¿å… ITN è½¬æ¢æ—¶æ— æ³•ä¿®æ”¹å·²ä¸Šå±çš„æ•°å­—
    fn split_stable_unstable(&self, text: &str) -> (String, String) {
        // ğŸ¯ ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœæ•´ä¸ªæ–‡æœ¬åŒ…å«ä¸­æ–‡æ•°å­—ï¼Œå…¨éƒ¨ä¿ç•™åœ¨ Preedit
        if Self::contains_chinese_number(text) {
            return (String::new(), text.to_string());
        }

        // å¦‚æœä¸åŒ…å«æ•°å­—ï¼ŒæŒ‰æ­£å¸¸é€»è¾‘åˆ†ç¦»
        const KEEP_LAST_CHARS: usize = 2; // ä¿ç•™æœ€å2ä¸ªå­—ç¬¦åœ¨ Preedit

        let chars: Vec<char> = text.chars().collect();

        if chars.len() <= KEEP_LAST_CHARS {
            // å…¨éƒ¨ä¸ç¨³å®š
            return (String::new(), text.to_string());
        }

        let stable_count = chars.len() - KEEP_LAST_CHARS;
        let stable: String = chars[..stable_count].iter().collect();
        let unstable: String = chars[stable_count..].iter().collect();

        (stable, unstable)
    }

    /// æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡æ•°å­—å­—ç¬¦
    ///
    /// ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å»¶è¿Ÿä¸Šå±ï¼Œç­‰å¾… ITN å¤„ç†
    fn contains_chinese_number(text: &str) -> bool {
        text.chars().any(|c| matches!(c,
            'é›¶' | 'ä¸€' | 'äºŒ' | 'ä¸‰' | 'å››' | 'äº”' | 'å…­' | 'ä¸ƒ' | 'å…«' | 'ä¹' |
            'å' | 'ç™¾' | 'åƒ' | 'ä¸‡' | 'äº¿' | 'ç‚¹'
        ))
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆå¸¦æ ‡ç‚¹ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result_with_punctuation(&mut self) -> String {
        let result = if let Some(stream) = &self.asr_stream {
            // è·å–è¯¦ç»†ç»“æœï¼ˆåŒ…å« Token å’Œæ—¶é—´æˆ³ï¼‰
            let detailed_result = stream.get_detailed_result(&self.asr_recognizer);

            tracing::debug!("ğŸ“Š è¯†åˆ«ç»“æœè¯¦æƒ…: text='{}', token_count={}",
                detailed_result.text, detailed_result.tokens.len());

            if detailed_result.is_empty() {
                tracing::warn!("âš ï¸  è¯†åˆ«ç»“æœä¸ºç©º");
                String::new()
            } else {
                // æ‰“å°æ‰€æœ‰ Token ä¿¡æ¯
                for (i, token) in detailed_result.tokens.iter().enumerate() {
                    tracing::debug!("  Token[{}]: '{}' ({}ms - {}ms, duration={}ms)",
                        i, token.text, token.start_time_ms, token.end_time_ms, token.duration_ms());
                }

                // å¤„ç†æ¯ä¸ª Tokenï¼Œæ·»åŠ æ ‡ç‚¹
                let mut final_text = String::new();

                for token in &detailed_result.tokens {
                    // è½¬æ¢ä¸º TokenInfo
                    let token_info = token.to_token_info();

                    // å¤„ç† Tokenï¼ˆå¯èƒ½åœ¨å‰é¢æ·»åŠ é€—å·ï¼‰
                    if let Some(processed_token) = self.punctuation_engine.process_token(token_info) {
                        tracing::debug!("  å¤„ç† Token: '{}' -> '{}'", token.text, processed_token);
                        final_text.push_str(&processed_token);
                    } else {
                        tracing::debug!("  Token è¢«è¿‡æ»¤: '{}'", token.text);
                    }
                }

                // æ£€æµ‹ VAD èƒ½é‡å˜åŒ–ï¼ˆç”¨äºé—®å·æ£€æµ‹ï¼‰
                let energy_rising = self.endpoint_detector.analyze_energy_trend();

                // è·å–è¯­éŸ³æŒç»­æ—¶é—´ç”¨äºæ ‡ç‚¹å†³ç­–
                let speech_duration_ms = self.endpoint_detector.speech_duration().as_millis() as u64;

                tracing::debug!("ğŸ”š å‡†å¤‡æ·»åŠ å¥å°¾æ ‡ç‚¹: speech_duration_ms={}, energy_rising={}",
                    speech_duration_ms, energy_rising);

                // æ·»åŠ å¥å°¾æ ‡ç‚¹
                let ending = self.punctuation_engine.finalize_sentence(
                    speech_duration_ms,
                    energy_rising,
                );

                tracing::debug!("  å¥å°¾æ ‡ç‚¹: '{}'", ending);
                final_text.push_str(&ending);

                tracing::info!("âœ… æ ‡ç‚¹å¤„ç†å®Œæˆ: '{}'", final_text);
                final_text
            }
        } else {
            tracing::warn!("âš ï¸  ASR æµä¸ºç©º");
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }

    /// è·å–æœ€ç»ˆè¯†åˆ«ç»“æœï¼ˆä¸å¸¦æ ‡ç‚¹ï¼ŒåŸå§‹æ–‡æœ¬ï¼‰
    ///
    /// è°ƒç”¨æ­¤æ–¹æ³•åä¼šè‡ªåŠ¨é‡ç½®ç®¡é“çŠ¶æ€
    pub fn get_final_result(&mut self) -> String {
        let result = if let Some(stream) = &self.asr_stream {
            stream.get_result(&self.asr_recognizer)
        } else {
            String::new()
        };

        // é‡ç½®ç®¡é“ä»¥å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ«
        let _ = self.reset();

        result
    }
}

impl Drop for StreamingPipeline {
    fn drop(&mut self) {
        // ç¡®ä¿ ASR æµåœ¨ç®¡é“é”€æ¯å‰è¢«æ¸…ç†
        if let Some(mut stream) = self.asr_stream.take() {
            stream.reset(&self.asr_recognizer);
        }
    }
}

/// ç®¡é“ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct PipelineStats {
    /// å¤„ç†çš„æ€»å¸§æ•°
    pub total_frames: u64,
    /// é€å…¥ ASR çš„å¸§æ•°
    pub asr_frames: u64,
    /// è¯­éŸ³æŒç»­æ—¶é—´ (ms)
    pub speech_duration_ms: u64,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_pipeline_state_transitions() {
        assert_eq!(PipelineState::Idle, PipelineState::Idle);
        assert_ne!(PipelineState::Idle, PipelineState::Recognizing);
    }
}
