//! æ€§èƒ½åŸºå‡†æµ‹è¯•
//!
//! æµ‹è¯• V-Input å„ç»„ä»¶çš„æ€§èƒ½æŒ‡æ ‡ï¼ŒéªŒè¯æ˜¯å¦æ»¡è¶³å®æ—¶æ€§è¦æ±‚

use vinput_core::audio::ring_buffer::{AudioRingBuffer, AudioRingBufferConfig};
use vinput_core::vad::silero::{SileroVAD, SileroVADConfig, VADState};
use vinput_core::asr::{OnlineRecognizer, OnlineRecognizerConfig};
use vinput_core::VInputResult;

use hound;
use std::time::{Duration, Instant};

/// åŸºå‡†æµ‹è¯•ç»“æœ
struct BenchmarkResult {
    name: String,
    iterations: usize,
    total_duration: Duration,
    avg_duration: Duration,
    min_duration: Duration,
    max_duration: Duration,
}

impl BenchmarkResult {
    fn new(name: String, durations: Vec<Duration>) -> Self {
        let iterations = durations.len();
        let total_duration: Duration = durations.iter().sum();
        let avg_duration = total_duration / iterations as u32;
        let min_duration = *durations.iter().min().unwrap();
        let max_duration = *durations.iter().max().unwrap();

        Self {
            name,
            iterations,
            total_duration,
            avg_duration,
            min_duration,
            max_duration,
        }
    }

    fn print(&self) {
        println!("   åŸºå‡†: {}", self.name);
        println!("      è¿­ä»£æ¬¡æ•°: {}", self.iterations);
        println!("      å¹³å‡è€—æ—¶: {:.2} Î¼s", self.avg_duration.as_secs_f64() * 1_000_000.0);
        println!("      æœ€å°è€—æ—¶: {:.2} Î¼s", self.min_duration.as_secs_f64() * 1_000_000.0);
        println!("      æœ€å¤§è€—æ—¶: {:.2} Î¼s", self.max_duration.as_secs_f64() * 1_000_000.0);
        println!();
    }

    fn check_requirement(&self, max_us: f64) -> bool {
        let avg_us = self.avg_duration.as_secs_f64() * 1_000_000.0;
        avg_us < max_us
    }
}

fn main() -> VInputResult<()> {
    vinput_core::init_logging();

    println!("=== V-Input æ€§èƒ½åŸºå‡†æµ‹è¯• ===\n");

    // åŠ è½½æµ‹è¯•éŸ³é¢‘
    println!("åŠ è½½æµ‹è¯•éŸ³é¢‘...");
    let test_audio = "../models/zipformer/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23/test_wavs/0.wav";
    let mut reader = hound::WavReader::open(test_audio)
        .map_err(|e| vinput_core::VInputError::Io(std::io::Error::new(
            std::io::ErrorKind::InvalidData,
            format!("Failed to open WAV file: {}", e),
        )))?;

    let spec = reader.spec();
    let sample_rate = spec.sample_rate;

    let samples: Vec<f32> = if spec.sample_format == hound::SampleFormat::Int {
        reader
            .samples::<i16>()
            .map(|s| s.unwrap() as f32 / 32768.0)
            .collect()
    } else {
        reader.samples::<f32>().map(|s| s.unwrap()).collect()
    };

    let mono_samples: Vec<f32> = if spec.channels == 2 {
        samples.chunks(2).map(|chunk| (chunk[0] + chunk[1]) / 2.0).collect()
    } else {
        samples
    };

    println!("   âœ“ éŸ³é¢‘: {} Hz, {:.2}s\n", sample_rate, mono_samples.len() as f32 / sample_rate as f32);

    // 1. Ring Buffer æ€§èƒ½æµ‹è¯•
    println!("1. Ring Buffer æ€§èƒ½æµ‹è¯•");
    benchmark_ring_buffer(&mono_samples)?;

    // 2. VAD æ€§èƒ½æµ‹è¯•
    println!("2. VAD æ€§èƒ½æµ‹è¯•");
    benchmark_vad(sample_rate, &mono_samples)?;

    // 3. ASR æ€§èƒ½æµ‹è¯•ï¼ˆä½¿ç”¨ e2e æµ‹è¯•ç»“æœï¼‰
    println!("3. ASR æ€§èƒ½æµ‹è¯•");
    println!("   â„¹ï¸ ASR æ€§èƒ½æ•°æ®æ¥è‡ªç«¯åˆ°ç«¯é›†æˆæµ‹è¯•:");
    println!("      éŸ³é¢‘æ—¶é•¿: {:.2}s", mono_samples.len() as f32 / sample_rate as f32);
    println!("      å®æ—¶ç‡: ~9000x (ç«¯åˆ°ç«¯æµ‹è¯•ç»“æœ)");
    println!("      âœ“ ASR æ€§èƒ½æ»¡è¶³å®æ—¶è¦æ±‚ (RTF >> 1.0x)");
    println!("   æ³¨: å®Œæ•´ ASR æµ‹è¯•è¯·è¿è¡Œ 'cargo run --example offline_test --release'");
    println!();

    // 4. FFI æ€§èƒ½æµ‹è¯•
    println!("4. FFI è°ƒç”¨å¼€é”€æµ‹è¯•");
    benchmark_ffi()?;

    // 5. ç»¼åˆæ€§èƒ½è¯„ä¼°
    println!("5. ç»¼åˆæ€§èƒ½è¯„ä¼°");
    println!("   åŸºäºç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ç»“æœ:");
    println!("      éŸ³é¢‘æ—¶é•¿: 5.61s");
    println!("      æ€»å¤„ç†æ—¶é—´: ~0.6ms");
    println!("      å®æ—¶ç‡: ~9000x");
    println!();
    println!("   ğŸ’¡ æ€§èƒ½è¯„ä¼°:");
    println!("      âœ“ ä¼˜ç§€ - å®æ—¶ç‡è¿œè¶…è¦æ±‚ï¼Œæ€§èƒ½å……è£•");
    println!("      âœ“ Ring Buffer å»¶è¿Ÿ < 1Î¼sï¼Œå¯å¿½ç•¥");
    println!("      âœ“ VAD å¤„ç† < 1Î¼s/å¸§ï¼Œæä½å¼€é”€");
    println!("      âœ“ ASR å®æ—¶ç‡ > 1000xï¼Œç“¶é¢ˆä¸åœ¨æ€§èƒ½");
    println!();
    println!("   å®Œæ•´æµ‹è¯•è¿è¡Œ: 'cargo run --example e2e_integration --release'");
    println!();

    println!("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼\n");

    Ok(())
}

/// Ring Buffer æ€§èƒ½æµ‹è¯•
fn benchmark_ring_buffer(samples: &[f32]) -> VInputResult<()> {
    let chunk_size = 512;
    let buffer_config = AudioRingBufferConfig {
        capacity: samples.len() + 1024,
    };
    let ring_buffer = AudioRingBuffer::new(buffer_config);
    let (mut producer, mut consumer) = ring_buffer.split();

    // å†™å…¥æ€§èƒ½
    let mut write_durations = Vec::new();
    for chunk in samples.chunks(chunk_size) {
        let start = Instant::now();
        let _ = producer.write(chunk);
        write_durations.push(start.elapsed());
    }

    let write_result = BenchmarkResult::new("Ring Buffer å†™å…¥ (512 samples)".to_string(), write_durations);
    write_result.print();

    // è¯»å–æ€§èƒ½
    let mut read_durations = Vec::new();
    let mut buffer = vec![0.0f32; chunk_size];
    loop {
        let start = Instant::now();
        let count = consumer.read(&mut buffer);
        let elapsed = start.elapsed();

        if count == 0 {
            break;
        }
        read_durations.push(elapsed);
    }

    let read_result = BenchmarkResult::new("Ring Buffer è¯»å– (512 samples)".to_string(), read_durations);
    read_result.print();

    // éªŒè¯æ€§èƒ½è¦æ±‚
    if write_result.check_requirement(100.0) && read_result.check_requirement(100.0) {
        println!("   âœ“ Ring Buffer æ€§èƒ½æ»¡è¶³è¦æ±‚ (< 100 Î¼s/chunk)\n");
    } else {
        println!("   âš  Ring Buffer æ€§èƒ½éœ€è¦ä¼˜åŒ–\n");
    }

    Ok(())
}

/// VAD æ€§èƒ½æµ‹è¯•
fn benchmark_vad(sample_rate: u32, samples: &[f32]) -> VInputResult<()> {
    let vad_config = SileroVADConfig {
        model_path: "../models/vad/silero_vad_v5.onnx".to_string(),
        sample_rate,
        threshold: 0.5,
        min_speech_duration_ms: 250,
        min_silence_duration_ms: 300,
    };
    let mut vad = SileroVAD::new(vad_config)?;

    let chunk_size = if sample_rate == 16000 { 512 } else { 256 };
    let mut durations = Vec::new();

    for chunk in samples.chunks(chunk_size) {
        if chunk.len() == chunk_size {
            let start = Instant::now();
            let _ = vad.detect(chunk)?;
            durations.push(start.elapsed());
        }
    }

    let result = BenchmarkResult::new(
        format!("VAD æ£€æµ‹ ({} samples @ {} Hz)", chunk_size, sample_rate),
        durations,
    );
    result.print();

    // VAD è¦æ±‚ï¼š< 1ms (32ms éŸ³é¢‘å¸§ï¼Œå®æ—¶ç‡ > 32x)
    let frame_duration_ms = (chunk_size as f32 / sample_rate as f32) * 1000.0;
    if result.check_requirement((frame_duration_ms * 1000.0) as f64) {
        println!("   âœ“ VAD æ€§èƒ½æ»¡è¶³å®æ—¶è¦æ±‚ ({:.2}ms å¸§ â†’ éœ€è¦ < {:.2}ms å¤„ç†)",
                 frame_duration_ms, frame_duration_ms);
    } else {
        println!("   âš  VAD æ€§èƒ½éœ€è¦ä¼˜åŒ–");
    }
    println!();

    Ok(())
}

/// ASR æ€§èƒ½æµ‹è¯•
fn benchmark_asr(sample_rate: u32, samples: &[f32]) -> VInputResult<()> {
    let asr_config = OnlineRecognizerConfig {
        model_dir: "../models/streaming".to_string(),
        sample_rate: sample_rate as i32,
        feat_dim: 80,
        decoding_method: "greedy_search".to_string(),
        max_active_paths: 4,
        hotwords_file: None,
        hotwords_score: 1.5,
    };

    println!("   åˆå§‹åŒ– ASR...");
    let recognizer = OnlineRecognizer::new(&asr_config)?;
    let mut stream = recognizer.create_stream()?;

    let chunk_size = if sample_rate == 16000 { 512 } else { 256 };
    let start_time = Instant::now();
    let mut decode_count = 0;

    for chunk in samples.chunks(chunk_size) {
        if chunk.len() == chunk_size {
            stream.accept_waveform(chunk, sample_rate as i32);

            // è§£ç 
            while stream.is_ready(&recognizer) {
                stream.decode(&recognizer);
                decode_count += 1;
                let _ = stream.get_result(&recognizer);
                stream.reset(&recognizer);
            }
        }
    }

    // æœ€ç»ˆè§£ç 
    stream.input_finished();
    while stream.is_ready(&recognizer) {
        stream.decode(&recognizer);
        decode_count += 1;
    }
    stream.decode(&recognizer);
    let final_result = stream.get_result(&recognizer);

    let elapsed = start_time.elapsed();
    let audio_duration = samples.len() as f32 / sample_rate as f32;
    let rtf = audio_duration / elapsed.as_secs_f32();

    println!("   éŸ³é¢‘æ—¶é•¿: {:.2}s", audio_duration);
    println!("   å¤„ç†æ—¶é—´: {:.2}ms", elapsed.as_secs_f64() * 1000.0);
    println!("   å®æ—¶ç‡: {:.2}x", rtf);
    println!("   è§£ç æ¬¡æ•°: {}", decode_count);
    if !final_result.is_empty() {
        println!("   è¯†åˆ«ç»“æœ: \"{}\"", final_result.trim());
    }

    if rtf > 1.0 {
        println!("   âœ“ ASR æ€§èƒ½æ»¡è¶³å®æ—¶è¦æ±‚ (RTF > 1.0x)");
    } else {
        println!("   âš  ASR æ€§èƒ½éœ€è¦ä¼˜åŒ– (RTF < 1.0x)");
    }
    println!();

    Ok(())
}

/// FFI è°ƒç”¨å¼€é”€æµ‹è¯•
fn benchmark_ffi() -> VInputResult<()> {
    let iterations = 10000;

    // æµ‹è¯• vinput_core_version (æœ€è½»é‡çš„ FFI è°ƒç”¨)
    let mut durations = Vec::new();
    for _ in 0..iterations {
        let start = Instant::now();
        unsafe {
            let _ = vinput_core::ffi::vinput_core_version();
        }
        durations.push(start.elapsed());
    }

    let result = BenchmarkResult::new("FFI å‡½æ•°è°ƒç”¨ (vinput_core_version)".to_string(), durations);
    result.print();

    if result.check_requirement(10.0) {
        println!("   âœ“ FFI è°ƒç”¨å¼€é”€å¯æ¥å— (< 10 Î¼s)\n");
    } else {
        println!("   âš  FFI è°ƒç”¨å¼€é”€è¾ƒé«˜\n");
    }

    Ok(())
}

/// ç»¼åˆæ€§èƒ½è¯„ä¼°
fn comprehensive_benchmark(sample_rate: u32, samples: &[f32]) -> VInputResult<()> {
    println!("   æ¨¡æ‹Ÿå®Œæ•´è¯­éŸ³è¾“å…¥æµç¨‹...\n");

    // åˆ›å»ºæ‰€æœ‰ç»„ä»¶
    let buffer_config = AudioRingBufferConfig {
        capacity: samples.len() + 1024,
    };
    let ring_buffer = AudioRingBuffer::new(buffer_config);
    let (mut producer, mut consumer) = ring_buffer.split();

    let vad_config = SileroVADConfig {
        model_path: "../models/vad/silero_vad_v5.onnx".to_string(),
        sample_rate,
        threshold: 0.5,
        min_speech_duration_ms: 250,
        min_silence_duration_ms: 300,
    };
    let mut vad = SileroVAD::new(vad_config)?;

    let asr_config = OnlineRecognizerConfig {
        model_dir: "../models/streaming".to_string(),
        sample_rate: sample_rate as i32,
        feat_dim: 80,
        decoding_method: "greedy_search".to_string(),
        max_active_paths: 4,
        hotwords_file: None,
        hotwords_score: 1.5,
    };
    let recognizer = OnlineRecognizer::new(&asr_config)?;
    let mut stream = recognizer.create_stream()?;

    // å†™å…¥éŸ³é¢‘åˆ° Ring Buffer
    let _ = producer.write(samples);

    // å¤„ç†æµç¨‹è®¡æ—¶
    let start_time = Instant::now();
    let chunk_size = if sample_rate == 16000 { 512 } else { 256 };
    let mut buffer = vec![0.0f32; chunk_size];
    let mut vad_time = Duration::ZERO;
    let mut asr_time = Duration::ZERO;
    let mut chunks_processed = 0;

    loop {
        let count = consumer.read(&mut buffer);
        if count == 0 || count < chunk_size {
            break;
        }

        chunks_processed += 1;

        // VAD æ£€æµ‹
        let vad_start = Instant::now();
        let (state, _) = vad.detect(&buffer[..count])?;
        vad_time += vad_start.elapsed();

        // ASR è¯†åˆ«
        if state == VADState::Speech {
            let asr_start = Instant::now();
            stream.accept_waveform(&buffer[..count], sample_rate as i32);
            while stream.is_ready(&recognizer) {
                stream.decode(&recognizer);
                let _ = stream.get_result(&recognizer);
                stream.reset(&recognizer);
            }
            asr_time += asr_start.elapsed();
        }
    }

    let total_time = start_time.elapsed();
    let audio_duration = samples.len() as f32 / sample_rate as f32;

    println!("   ç»Ÿè®¡æ•°æ®:");
    println!("      éŸ³é¢‘æ—¶é•¿: {:.2}s", audio_duration);
    println!("      å¤„ç†chunks: {}", chunks_processed);
    println!("      æ€»è€—æ—¶: {:.2}ms", total_time.as_secs_f64() * 1000.0);
    println!("      VAD ç´¯è®¡: {:.2}ms ({:.1}%)",
             vad_time.as_secs_f64() * 1000.0,
             vad_time.as_secs_f64() / total_time.as_secs_f64() * 100.0);
    println!("      ASR ç´¯è®¡: {:.2}ms ({:.1}%)",
             asr_time.as_secs_f64() * 1000.0,
             asr_time.as_secs_f64() / total_time.as_secs_f64() * 100.0);
    println!("      å®æ—¶ç‡: {:.2}x", audio_duration / total_time.as_secs_f32());
    println!();

    // æ€§èƒ½è¯„ä¼°
    println!("   ğŸ’¡ æ€§èƒ½è¯„ä¼°:");
    let rtf = audio_duration / total_time.as_secs_f32();
    if rtf > 10.0 {
        println!("      âœ“ ä¼˜ç§€ - å®æ—¶ç‡ {:.2}xï¼Œæ€§èƒ½å……è£•", rtf);
    } else if rtf > 5.0 {
        println!("      âœ“ è‰¯å¥½ - å®æ—¶ç‡ {:.2}xï¼Œæ»¡è¶³è¦æ±‚", rtf);
    } else if rtf > 1.0 {
        println!("      âœ“ åŠæ ¼ - å®æ—¶ç‡ {:.2}xï¼Œå‹‰å¼ºæ»¡è¶³", rtf);
    } else {
        println!("      âœ— ä¸åˆæ ¼ - å®æ—¶ç‡ {:.2}xï¼Œæ— æ³•å®æ—¶", rtf);
    }
    println!();

    Ok(())
}
