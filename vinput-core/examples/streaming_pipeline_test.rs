//! æµå¼è¯†åˆ«ç®¡é“æµ‹è¯•ç¤ºä¾‹
//!
//! æ¼”ç¤º VAD-ASR æµå¼è¯†åˆ«ç®¡é“çš„å®Œæ•´æµç¨‹
//!
//! ä½¿ç”¨æ–¹æ³•ï¼š
//! ```bash
//! cargo run --example streaming_pipeline_test --features vad-onnx
//! ```

use vinput_core::asr::OnlineRecognizerConfig;
use vinput_core::streaming::{PipelineState, StreamingConfig, StreamingPipeline};
use vinput_core::vad::VadConfig;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    #[cfg(feature = "debug-logs")]
    vinput_core::init_logging();

    println!("=== V-Input æµå¼è¯†åˆ«ç®¡é“æµ‹è¯• ===\n");

    // 1. é…ç½®ç®¡é“
    let streaming_config = StreamingConfig {
        vad_config: VadConfig::push_to_talk_default(),
        asr_config: OnlineRecognizerConfig {
            model_dir: "models/streaming".to_string(), // Sherpa-ONNX æ¨¡å‹ç›®å½•
            sample_rate: 16000,
            feat_dim: 80,
            decoding_method: "greedy_search".to_string(),
            max_active_paths: 4,
            hotwords_file: None,
            hotwords_score: 1.5,
        },
        max_silence_duration_ms: 3000,
        enable_endpoint_detection: true,
    };

    println!("ğŸ“‹ é…ç½®:");
    println!("  - VAD æ¨¡å¼: {:?}", streaming_config.vad_config.mode);
    println!("  - VAD å¯åŠ¨é˜ˆå€¼: {}", streaming_config.vad_config.hysteresis.start_threshold);
    println!("  - ASR æ¨¡å‹: {}", streaming_config.asr_config.model_dir);
    println!("  - é‡‡æ ·ç‡: {} Hz", streaming_config.asr_config.sample_rate);
    println!();

    // 2. åˆ›å»ºç®¡é“
    println!("ğŸ”§ åˆ›å»ºæµå¼è¯†åˆ«ç®¡é“...");
    let mut pipeline = match StreamingPipeline::new(streaming_config) {
        Ok(p) => {
            println!("âœ… ç®¡é“åˆ›å»ºæˆåŠŸ");
            p
        }
        Err(e) => {
            eprintln!("âŒ ç®¡é“åˆ›å»ºå¤±è´¥: {}", e);
            eprintln!("\nè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ° models/ ç›®å½•ï¼š");
            eprintln!("  - models/silero-vad/silero_vad.onnx (VAD æ¨¡å‹)");
            eprintln!("  - models/streaming/*.onnx (ASR æ¨¡å‹)");
            return Err(e.into());
        }
    };
    println!();

    // 3. æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥æµ‹è¯•
    println!("ğŸ¤ æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥æµ‹è¯•\n");

    // æ¨¡æ‹Ÿé™éŸ³ (ä½èƒ½é‡)
    println!("1ï¸âƒ£  å‘é€é™éŸ³å¸§...");
    let silence: Vec<f32> = vec![0.0; 512];
    for _ in 0..10 {
        let result = pipeline.process(&silence)?;
        print_result(&result, false);
    }

    // æ¨¡æ‹Ÿè¯­éŸ³ (é«˜èƒ½é‡)
    println!("\n2ï¸âƒ£  å‘é€è¯­éŸ³å¸§...");
    let speech: Vec<f32> = (0..512)
        .map(|i| (i as f32 * 0.01).sin() * 0.1)
        .collect();

    for i in 0..50 {
        let result = pipeline.process(&speech)?;
        print_result(&result, i % 5 == 0); // æ¯ 5 å¸§æ‰“å°ä¸€æ¬¡

        if result.is_final {
            println!("\nâœ… è¯†åˆ«å®Œæˆï¼æœ€ç»ˆç»“æœ: \"{}\"", result.partial_result);
            break;
        }
    }

    // é‡ç½®ç®¡é“
    println!("\n3ï¸âƒ£  é‡ç½®ç®¡é“...");
    pipeline.reset()?;
    println!("âœ… ç®¡é“å·²é‡ç½®");

    // æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    let stats = pipeline.stats();
    println!("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:");
    println!("  - æ€»å¸§æ•°: {}", stats.total_frames);
    println!("  - ASR å¸§æ•°: {}", stats.asr_frames);
    println!("  - è¯­éŸ³æ—¶é•¿: {} ms", stats.speech_duration_ms);

    println!("\nâœ… æµ‹è¯•å®Œæˆï¼");
    println!("\nğŸ’¡ æç¤º:");
    println!("  - è¦ä½¿ç”¨çœŸå®éº¦å…‹é£è¾“å…¥ï¼Œè¯·å‚è€ƒ examples/realtime_recognition.rs");
    println!("  - è¦å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼Œè¯·ä½¿ç”¨: VINPUT_LOG=debug cargo run --example streaming_pipeline_test --features debug-logs,vad-onnx");

    Ok(())
}

fn print_result(result: &vinput_core::streaming::StreamingResult, verbose: bool) {
    if !verbose {
        return;
    }

    println!(
        "  VAD: {:?} | Pipeline: {:?} | Prob: {:.3} | Partial: \"{}\"",
        result.vad_state,
        result.pipeline_state,
        result.speech_prob,
        result.partial_result
    );
}
