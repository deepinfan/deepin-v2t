//! ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
//!
//! éªŒè¯å®Œæ•´çš„è¯­éŸ³è¯†åˆ«æµç¨‹ï¼š
//! éŸ³é¢‘åŠ è½½ -> Ring Buffer -> VAD -> ASR -> ç»“æœè¾“å‡º

use vinput_core::audio::ring_buffer::{AudioRingBuffer, AudioRingBufferConfig};
use vinput_core::vad::silero::{SileroVAD, SileroVADConfig, VADState};
use vinput_core::asr::{OnlineRecognizer, OnlineRecognizerConfig};
use vinput_core::VInputResult;

use hound;
use std::time::Instant;

fn main() -> VInputResult<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    vinput_core::init_logging();

    println!("=== V-Input ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• ===\n");

    // 1. åŠ è½½æµ‹è¯•éŸ³é¢‘
    println!("1. åŠ è½½æµ‹è¯•éŸ³é¢‘...");
    let test_audio = "../models/zipformer/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23/test_wavs/0.wav";

    let mut reader = hound::WavReader::open(test_audio)
        .map_err(|e| vinput_core::VInputError::Io(std::io::Error::new(
            std::io::ErrorKind::InvalidData,
            format!("Failed to open WAV file: {}", e),
        )))?;

    let spec = reader.spec();
    let sample_rate = spec.sample_rate;

    // è¯»å–éŸ³é¢‘æ ·æœ¬å¹¶è½¬æ¢ä¸º f32
    let samples: Vec<f32> = if spec.sample_format == hound::SampleFormat::Int {
        if spec.bits_per_sample == 16 {
            reader
                .samples::<i16>()
                .map(|s| s.unwrap() as f32 / 32768.0)
                .collect()
        } else {
            eprintln!("âŒ é”™è¯¯: ä¸æ”¯æŒçš„ä½æ·±åº¦: {}", spec.bits_per_sample);
            std::process::exit(1);
        }
    } else {
        reader
            .samples::<f32>()
            .map(|s| s.unwrap())
            .collect()
    };

    // å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
    let mono_samples: Vec<f32> = if spec.channels == 2 {
        samples.chunks(2).map(|chunk| (chunk[0] + chunk[1]) / 2.0).collect()
    } else {
        samples
    };

    println!("   âœ“ åŠ è½½æˆåŠŸ: {} Hz, {} æ ·æœ¬, {:.2}s",
             sample_rate, mono_samples.len(),
             mono_samples.len() as f32 / sample_rate as f32);
    println!();

    // 2. åˆ›å»º Ring Buffer
    println!("2. åˆ›å»º Ring Buffer...");
    // ç¡®ä¿ buffer è¶³å¤Ÿå¤§ä»¥å®¹çº³æ•´ä¸ªéŸ³é¢‘æ–‡ä»¶
    let buffer_capacity = mono_samples.len() + 1024;
    let buffer_config = AudioRingBufferConfig {
        capacity: buffer_capacity,
    };
    let ring_buffer = AudioRingBuffer::new(buffer_config);
    let (mut producer, mut consumer) = ring_buffer.split();
    println!("   âœ“ Ring Buffer åˆ›å»ºæˆåŠŸ (capacity: {})", buffer_capacity);
    println!();

    // 3. åˆå§‹åŒ– VAD
    println!("3. åˆå§‹åŒ– Silero VAD...");
    let vad_config = SileroVADConfig {
        model_path: "../models/vad/silero_vad_v5.onnx".to_string(),
        sample_rate,
        threshold: 0.5,
        min_speech_duration_ms: 250,
        min_silence_duration_ms: 300,
    };
    let mut vad = SileroVAD::new(vad_config)?;
    println!("   âœ“ VAD åˆå§‹åŒ–æˆåŠŸ");
    println!();

    // 4. åˆå§‹åŒ– ASR
    println!("4. åˆå§‹åŒ– sherpa-onnx ASR...");
    let asr_config = OnlineRecognizerConfig {
        model_dir: "../models/streaming".to_string(),
        sample_rate: sample_rate as i32,
        feat_dim: 80,
        decoding_method: "greedy_search".to_string(),
        max_active_paths: 4,
        hotwords_file: None,
        hotwords_score: 1.5,
    };
    let recognizer = OnlineRecognizer::new(&asr_config)?;
    println!("   âœ“ ASR åˆå§‹åŒ–æˆåŠŸ");
    println!();

    // 5. ç«¯åˆ°ç«¯å¤„ç†æµç¨‹
    println!("5. ç«¯åˆ°ç«¯å¤„ç†æµç¨‹...");
    println!("   æ¨¡æ‹ŸéŸ³é¢‘æµå¤„ç†ï¼š");
    println!();

    let start_time = Instant::now();
    let chunk_size = if sample_rate == 16000 { 512 } else { 256 };
    let mut total_chunks = 0;
    let mut speech_chunks = 0;
    let mut silence_chunks = 0;
    let mut recognition_count = 0;

    // å°†éŸ³é¢‘æ•°æ®å†™å…¥ Ring Bufferï¼ˆæ¨¡æ‹ŸéŸ³é¢‘æ•è·ï¼‰
    let write_result = producer.write(&mono_samples);
    match write_result {
        Ok(written) => {
            println!("   âœ“ å†™å…¥ Ring Buffer: {} æ ·æœ¬", written);
        }
        Err(e) => {
            println!("   âš  Ring Buffer å†™å…¥è­¦å‘Š: {:?}", e);
        }
    }

    // ä» Ring Buffer è¯»å–å¹¶å¤„ç†ï¼ˆæ¨¡æ‹Ÿå®æ—¶å¤„ç†ï¼‰
    let mut chunk_buffer = vec![0.0f32; chunk_size];
    let mut current_state = VADState::Silence;
    let mut stream = recognizer.create_stream()?;
    let mut speech_samples = Vec::new();

    loop {
        // ä» Ring Buffer è¯»å–ä¸€ä¸ª chunk
        let read_count = consumer.read(&mut chunk_buffer);
        if read_count == 0 {
            break; // æ²¡æœ‰æ›´å¤šæ•°æ®
        }

        total_chunks += 1;

        // VAD æ£€æµ‹ï¼ˆåªå¤„ç†å®Œæ•´çš„ chunkï¼‰
        if read_count < chunk_size {
            // æœ€åä¸€ä¸ªä¸å®Œæ•´çš„ chunkï¼Œè·³è¿‡ VAD æ£€æµ‹
            break;
        }

        let (new_state, is_endpoint) = vad.detect(&chunk_buffer[..read_count])?;

        match new_state {
            VADState::Speech => {
                speech_chunks += 1;
                if current_state != VADState::Speech {
                    println!("   ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (chunk #{})", total_chunks);
                    speech_samples.clear();
                }

                // æ”¶é›†è¯­éŸ³æ ·æœ¬
                speech_samples.extend_from_slice(&chunk_buffer[..read_count]);

                // é€å…¥ ASR è¯†åˆ«æµ
                stream.accept_waveform(&chunk_buffer[..read_count], sample_rate as i32);

                // å°è¯•è§£ç 
                while stream.is_ready(&recognizer) {
                    stream.decode(&recognizer);
                    let partial = stream.get_result(&recognizer);
                    if !partial.is_empty() && partial.trim() != "" {
                        println!("      âœ éƒ¨åˆ†è¯†åˆ«: \"{}\"", partial.trim());
                        stream.reset(&recognizer);
                    }
                }
            }
            VADState::Silence => {
                silence_chunks += 1;
                if current_state == VADState::Speech {
                    println!("   ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ (chunk #{})", total_chunks);
                    println!("      è¯­éŸ³æ®µé•¿åº¦: {:.2}s", speech_samples.len() as f32 / sample_rate as f32);

                    // è¯­éŸ³æ®µç»“æŸï¼Œæ ‡è®°è¾“å…¥å®Œæˆ
                    stream.input_finished();

                    // è·å–æœ€ç»ˆç»“æœ
                    while stream.is_ready(&recognizer) {
                        stream.decode(&recognizer);
                    }

                    stream.decode(&recognizer);
                    let final_result = stream.get_result(&recognizer);

                    if !final_result.is_empty() && final_result.trim() != "" {
                        recognition_count += 1;
                        println!("   âœ… æœ€ç»ˆè¯†åˆ« #{}: \"{}\"", recognition_count, final_result.trim());
                        println!();
                    }

                    // åˆ›å»ºæ–°çš„æµï¼Œå‡†å¤‡ä¸‹ä¸€æ®µ
                    stream = recognizer.create_stream()?;
                }
            }
        }

        current_state = new_state;

        // å¦‚æœ VAD æ£€æµ‹åˆ°ç«¯ç‚¹
        if is_endpoint {
            println!("   ğŸ“ VAD ç«¯ç‚¹æ£€æµ‹ (chunk #{})", total_chunks);
        }
    }

    // å¦‚æœæœ€åè¿˜åœ¨è¯­éŸ³çŠ¶æ€ï¼Œè·å–æœ€ç»ˆç»“æœ
    if current_state == VADState::Speech {
        println!("   ğŸ”‡ éŸ³é¢‘ç»“æŸï¼Œå¤„ç†å‰©ä½™è¯­éŸ³");
        stream.input_finished();

        while stream.is_ready(&recognizer) {
            stream.decode(&recognizer);
        }

        stream.decode(&recognizer);
        let final_result = stream.get_result(&recognizer);

        if !final_result.is_empty() && final_result.trim() != "" {
            recognition_count += 1;
            println!("   âœ… æœ€ç»ˆè¯†åˆ« #{}: \"{}\"", recognition_count, final_result.trim());
            println!();
        }
    }

    let elapsed = start_time.elapsed();

    // 6. ç»Ÿè®¡ç»“æœ
    println!("6. æµ‹è¯•ç»“æœç»Ÿè®¡ï¼š");
    println!("   æ€»å¤„ç†æ—¶é—´: {:.2}ms", elapsed.as_secs_f64() * 1000.0);
    println!("   éŸ³é¢‘æ—¶é•¿: {:.2}s", mono_samples.len() as f32 / sample_rate as f32);
    println!("   å®æ—¶ç‡: {:.2}x",
             (mono_samples.len() as f32 / sample_rate as f32) / elapsed.as_secs_f32());
    println!();
    println!("   æ€» chunk æ•°: {}", total_chunks);
    println!("   è¯­éŸ³ chunks: {} ({:.1}%)",
             speech_chunks,
             speech_chunks as f32 / total_chunks as f32 * 100.0);
    println!("   é™éŸ³ chunks: {} ({:.1}%)",
             silence_chunks,
             silence_chunks as f32 / total_chunks as f32 * 100.0);
    println!("   è¯†åˆ«ç»“æœæ•°: {}", recognition_count);
    println!();

    // 7. Ring Buffer ç»Ÿè®¡
    println!("7. Ring Buffer ç»Ÿè®¡ï¼š");
    let overrun_count = producer.overrun_count();
    println!("   æº¢å‡ºæ¬¡æ•°: {}", overrun_count);
    if overrun_count > 0 {
        println!("   âš  å‘ç”Ÿäº† {} æ¬¡æº¢å‡º", overrun_count);
    } else {
        println!("   âœ“ æ— æº¢å‡º");
    }
    println!();

    // 8. éªŒè¯ç»“è®º
    println!("âœ… ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•å®Œæˆï¼\n");
    println!("ğŸ’¡ Phase 0 éªŒè¯ç»“è®ºï¼š");
    println!("   âœ“ Ring Buffer ç”Ÿäº§è€…/æ¶ˆè´¹è€…æ¨¡å¼å·¥ä½œæ­£å¸¸");
    println!("   âœ“ VAD çŠ¶æ€æœºæ­£ç¡®æ£€æµ‹è¯­éŸ³æ®µ");
    println!("   âœ“ ASR è¯†åˆ«å™¨æˆåŠŸè¾“å‡ºæ–‡æœ¬");
    println!("   âœ“ å„ç»„ä»¶é›†æˆæµç•…ï¼Œæ— é˜»å¡");
    if elapsed.as_secs_f32() > 0.0 {
        let rtf = (mono_samples.len() as f32 / sample_rate as f32) / elapsed.as_secs_f32();
        if rtf > 1.0 {
            println!("   âœ“ å®æ—¶ç‡ {:.2}x > 1.0ï¼Œæ»¡è¶³å®æ—¶æ€§è¦æ±‚", rtf);
        } else {
            println!("   âš  å®æ—¶ç‡ {:.2}x < 1.0ï¼Œæ€§èƒ½éœ€è¦ä¼˜åŒ–", rtf);
        }
    }
    println!();
    println!("ğŸ“‹ Phase 1 å¾…å®ç°ï¼š");
    println!("   - é›†æˆ PipeWire å®é™…éŸ³é¢‘æ•è·");
    println!("   - é€šè¿‡ FFI æ¥å£å‘ Fcitx5 å‘é€å‘½ä»¤");
    println!("   - å®ç°å®Œæ•´çš„è¯­éŸ³è¾“å…¥è§¦å‘é€»è¾‘");
    println!("   - æ·»åŠ å€™é€‰è¯å±•ç¤ºå’Œé€‰æ‹©");
    println!();

    Ok(())
}
